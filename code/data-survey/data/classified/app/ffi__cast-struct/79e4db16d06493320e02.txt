Module: gorgonia.org/cu
Version: v0.9.2

Package: gorgonia.org/cu/dnn
File: generated_API.go
Line: 863

Imported (possibly among others) by: gorgonia/gorgonia

Label 1 (What is happening?): cast-struct
Label 2 (For what purpose?): ffi

--------------------------------------------------------------
Snippet line:

yDescPtr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&yDescInternals[0]))
--------------------------------------------------------------
+/- 5 lines context:


	yDescInternals := make([]C.cudnnTensorDescriptor_t, len(xDesc))
	for i := range yDesc {
		yDescInternals[i] = yDesc[i].internal
	}
	yDescPtr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&yDescInternals[0]))
	// call cudnnRNNForwardTraining
	return result(C.cudnnRNNForwardTraining(co.internal, rnnDesc.internal, C.int(seqLength), ptr, x.Pointer(), hxDesc.internal, hx.Pointer(), cxDesc.internal, cx.Pointer(), wDesc.internal, w.Pointer(), yDescPtr, y.Pointer(), hyDesc.internal, hy.Pointer(), cyDesc.internal, cy.Pointer(), workspace.Pointer(), C.size_t(workSpaceSizeInBytes), reserveSpace.Pointer(), C.size_t(reserveSpaceSizeInBytes)))
}

// RNNBackwardData executes the recurrent neural network described by rnnDesc with output gradients dy, dhy, dhc, weights w and input gradients dx, dhx, dcx. workspace is required for intermediate storage. The data in reserveSpace must have previously been generated by cudnnRNNForwardTraining. The same reserveSpace data must be used for future calls to cudnnRNNBackwardWeights if they execute on the same input data.
--------------------------------------------------------------
+/- 100 lines context:

	if len(xDesc) != seqLength {
		return 0, errors.Errorf("Incorrect xDesc length. Want %d. Got %d", seqLength, len(xDesc))
	}

	internals := make([]C.cudnnTensorDescriptor_t, len(xDesc))
	for i := range xDesc {
		internals[i] = xDesc[i].internal
	}
	ptr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&internals[0]))

	// call cudnnGetRNNWorkspaceSize
	err = result(C.cudnnGetRNNWorkspaceSize(co.internal, rnnDesc.internal, C.int(seqLength), ptr, &sizeInBytesC))
	sizeInBytes = uintptr(sizeInBytesC)
	return
}

// GetRNNTrainingReserveSize is used to query the amount of reserved space required for training the RNN described by rnnDesc with inputs dimensions defined by xDesc. The same reserved space buffer must be passed to cudnnRNNForwardTraining, cudnnRNNBackwardData and cudnnRNNBackwardWeights. Each of these calls overwrites the contents of the reserved space, however it can safely be backed up and restored between calls if reuse of the memory is desired.
func (co *Context) GetRNNTrainingReserveSize(rnnDesc *RNN, seqLength int, xDesc []*TensorDescriptor) (sizeInBytes uintptr, err error) {
	var sizeInBytesC C.size_t
	if len(xDesc) != seqLength {
		return 0, errors.Errorf("Incorrect xDesc length. Want %d. Got %d", seqLength, len(xDesc))
	}

	internals := make([]C.cudnnTensorDescriptor_t, len(xDesc))
	for i := range xDesc {
		internals[i] = xDesc[i].internal
	}
	ptr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&internals[0]))

	// call cudnnGetRNNTrainingReserveSize
	err = result(C.cudnnGetRNNTrainingReserveSize(co.internal, rnnDesc.internal, C.int(seqLength), ptr, &sizeInBytesC))
	sizeInBytes = uintptr(sizeInBytesC)
	return
}

// GetRNNParamsSize is used to query the amount of parameter space required to execute the RNN described by rnnDesc with inputs dimensions defined by xDesc.
func (co *Context) GetRNNParamsSize(rnnDesc *RNN, xDesc *TensorDescriptor, dataType DataType) (sizeInBytes uintptr, err error) {
	var sizeInBytesC C.size_t
	// call cudnnGetRNNParamsSize
	err = result(C.cudnnGetRNNParamsSize(co.internal, rnnDesc.internal, xDesc.internal, &sizeInBytesC, dataType.C()))
	sizeInBytes = uintptr(sizeInBytesC)
	return
}

// // GetRNNLinLayerMatrixParams is used to obtain a pointer and a descriptor of every RNN weight matrix in each pseudo-layer within the recurrent network defined by rnnDesc and its input width specified in xDesc.
// func (co *Context) GetRNNLinLayerMatrixParams(rnnDesc *RNN, layer int, xDesc *TensorDescriptor, wDesc *Filter, w Memory, linLayerID int) (linLayerMatDesc *Filter, linLayerMat TODO, err error) {
// 	// TODO: linLayerMatDesc cudnnFilterDescriptor_t
// 	// TODO: linLayerMat void**
// 	// call cudnnGetRNNLinLayerMatrixParams
// 	err = result(C.cudnnGetRNNLinLayerMatrixParams(co.internal, rnnDesc.internal, C.int(layer), xDesc.internal, wDesc.internal, w.Pointer(), C.int(linLayerID), linLayerMatDesc.internal, linLayerMat))
// 	return
// }

// // GetRNNLinLayerBiasParams is used to obtain a pointer and a descriptor of every RNN bias column vector in each pseudo-layer within the recurrent network defined by rnnDesc and its input width specified in xDesc.
// func (co *Context) GetRNNLinLayerBiasParams(rnnDesc *RNN, layer int, xDesc *TensorDescriptor, wDesc *Filter, w Memory, linLayerID int) (linLayerBiasDesc *Filter, linLayerBias TODO, err error) {
// 	// TODO: linLayerBiasDesc cudnnFilterDescriptor_t
// 	// TODO: linLayerBias void**
// 	// call cudnnGetRNNLinLayerBiasParams
// 	err = result(C.cudnnGetRNNLinLayerBiasParams(co.internal, rnnDesc.internal, C.int(layer), xDesc.internal, wDesc.internal, w.Pointer(), C.int(linLayerID), linLayerBiasDesc.internal, linLayerBias))
// 	return
// }

// RNNForwardInference executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w and outputs y, hy, cy. workspace is required for intermediate storage. RNNForwardInference does not store intermediate data required for training; cudnnRNNForwardTraining should be used for that purpose.
func (co *Context) RNNForwardInference(rnnDesc *RNN, seqLength int, xDesc []*TensorDescriptor, x Memory, hxDesc *TensorDescriptor, hx Memory, cxDesc *TensorDescriptor, cx Memory, wDesc *Filter, w Memory, yDesc []*TensorDescriptor, y Memory, hyDesc *TensorDescriptor, hy Memory, cyDesc *TensorDescriptor, cy Memory, workspace Memory, workSpaceSizeInBytes uintptr) error {
	// DOUBLECHECK: "cudnnRNNForwardInference" returns Memory type in Parameter 16
	if len(xDesc) != seqLength {
		return errors.Errorf("Incorrect xDesc length. Want %d. Got %d", seqLength, len(xDesc))
	}

	internals := make([]C.cudnnTensorDescriptor_t, len(xDesc))
	for i := range xDesc {
		internals[i] = xDesc[i].internal
	}
	xDescPtr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&internals[0]))

	yDescInternals := make([]C.cudnnTensorDescriptor_t, len(xDesc))
	for i := range yDesc {
		yDescInternals[i] = yDesc[i].internal
	}
	yDescPtr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&yDescInternals[0]))

	// call cudnnRNNForwardInference
	return result(C.cudnnRNNForwardInference(co.internal, rnnDesc.internal, C.int(seqLength), xDescPtr, x.Pointer(), hxDesc.internal, hx.Pointer(), cxDesc.internal, cx.Pointer(), wDesc.internal, w.Pointer(), yDescPtr, y.Pointer(), hyDesc.internal, hy.Pointer(), cyDesc.internal, cy.Pointer(), workspace.Pointer(), C.size_t(workSpaceSizeInBytes)))
}

// RNNForwardTraining executes the recurrent neural network described by rnnDesc with inputs x, hx, cx, weights w and outputs y, hy, cy. workspace is required for intermediate storage. reserveSpace stores data required for training. The same reserveSpace data must be used for future calls to cudnnRNNBackwardData and cudnnRNNBackwardWeights if these execute on the same input data.
//	reserveSpace is both an input and output
func (co *Context) RNNForwardTraining(rnnDesc *RNN, seqLength int, xDesc []*TensorDescriptor, x Memory, hxDesc *TensorDescriptor, hx Memory, cxDesc *TensorDescriptor, cx Memory, wDesc *Filter, w Memory, yDesc []*TensorDescriptor, y Memory, hyDesc *TensorDescriptor, hy Memory, cyDesc *TensorDescriptor, cy Memory, workspace Memory, workSpaceSizeInBytes uintptr, reserveSpace Memory, reserveSpaceSizeInBytes uintptr) error {
	// DOUBLECHECK: "cudnnRNNForwardTraining" returns Memory type in Parameter 16
	internals := make([]C.cudnnTensorDescriptor_t, len(xDesc))
	for i := range xDesc {
		internals[i] = xDesc[i].internal
	}
	ptr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&internals[0]))

	yDescInternals := make([]C.cudnnTensorDescriptor_t, len(xDesc))
	for i := range yDesc {
		yDescInternals[i] = yDesc[i].internal
	}
	yDescPtr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&yDescInternals[0]))
	// call cudnnRNNForwardTraining
	return result(C.cudnnRNNForwardTraining(co.internal, rnnDesc.internal, C.int(seqLength), ptr, x.Pointer(), hxDesc.internal, hx.Pointer(), cxDesc.internal, cx.Pointer(), wDesc.internal, w.Pointer(), yDescPtr, y.Pointer(), hyDesc.internal, hy.Pointer(), cyDesc.internal, cy.Pointer(), workspace.Pointer(), C.size_t(workSpaceSizeInBytes), reserveSpace.Pointer(), C.size_t(reserveSpaceSizeInBytes)))
}

// RNNBackwardData executes the recurrent neural network described by rnnDesc with output gradients dy, dhy, dhc, weights w and input gradients dx, dhx, dcx. workspace is required for intermediate storage. The data in reserveSpace must have previously been generated by cudnnRNNForwardTraining. The same reserveSpace data must be used for future calls to cudnnRNNBackwardWeights if they execute on the same input data.
//	reserveSpace is both an input and output
func (co *Context) RNNBackwardData(rnnDesc *RNN, seqLength int, yDesc []*TensorDescriptor, y Memory, dyDesc []*TensorDescriptor, dy Memory, dhyDesc *TensorDescriptor, dhy Memory, dcyDesc *TensorDescriptor, dcy Memory, wDesc *Filter, w Memory, hxDesc *TensorDescriptor, hx Memory, cxDesc *TensorDescriptor, cx Memory, dxDesc []*TensorDescriptor, dx Memory, dhxDesc *TensorDescriptor, dhx Memory, dcxDesc *TensorDescriptor, dcx Memory, workspace Memory, workSpaceSizeInBytes uintptr, reserveSpace Memory, reserveSpaceSizeInBytes uintptr) error {
	// DOUBLECHECK: "cudnnRNNBackwardData" returns Memory type in Parameter 22
	internals := make([]C.cudnnTensorDescriptor_t, len(yDesc))
	for i := range yDesc {
		internals[i] = yDesc[i].internal
	}
	ptr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&internals[0]))

	dyInternals := make([]C.cudnnTensorDescriptor_t, len(dyDesc))
	for i := range dyDesc {
		dyInternals[i] = dyDesc[i].internal
	}
	dyPtr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&dyInternals[0]))

	dxInternals := make([]C.cudnnTensorDescriptor_t, len(dxDesc))
	for i := range dyDesc {
		dxInternals[i] = dxDesc[i].internal
	}
	dxPtr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&dxInternals[0]))

	// call cudnnRNNBackwardData
	return result(C.cudnnRNNBackwardData(co.internal, rnnDesc.internal, C.int(seqLength), ptr, y.Pointer(), dyPtr, dy.Pointer(), dhyDesc.internal, dhy.Pointer(), dcyDesc.internal, dcy.Pointer(), wDesc.internal, w.Pointer(), hxDesc.internal, hx.Pointer(), cxDesc.internal, cx.Pointer(), dxPtr, dx.Pointer(), dhxDesc.internal, dhx.Pointer(), dcxDesc.internal, dcx.Pointer(), workspace.Pointer(), C.size_t(workSpaceSizeInBytes), reserveSpace.Pointer(), C.size_t(reserveSpaceSizeInBytes)))
}

// RNNBackwardWeights accumulates weight gradients dw from the recurrent neural network described by rnnDesc with inputs x, hx, and outputs y. The mode of operation in this case is additive, the weight gradients calculated will be added to those already existing in dw. workspace is required for intermediate storage. The data in reserveSpace must have previously been generated by cudnnRNNBackwardData.
//	dw is both an input and output
func (co *Context) RNNBackwardWeights(rnnDesc *RNN, seqLength int, xDesc []*TensorDescriptor, x Memory, hxDesc *TensorDescriptor, hx Memory, yDesc []*TensorDescriptor, y Memory, workspace Memory, workSpaceSizeInBytes uintptr, dwDesc *Filter, dw Memory, reserveSpace Memory, reserveSpaceSizeInBytes uintptr) error {
	internals := make([]C.cudnnTensorDescriptor_t, len(xDesc))
	for i := range xDesc {
		internals[i] = xDesc[i].internal
	}
	ptr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&internals[0]))

	yDescInternals := make([]C.cudnnTensorDescriptor_t, len(xDesc))
	for i := range yDesc {
		yDescInternals[i] = yDesc[i].internal
	}
	yDescPtr := (*C.cudnnTensorDescriptor_t)(unsafe.Pointer(&yDescInternals[0]))

	// call cudnnRNNBackwardWeights
	return result(C.cudnnRNNBackwardWeights(co.internal, rnnDesc.internal, C.int(seqLength), ptr, x.Pointer(), hxDesc.internal, hx.Pointer(), yDescPtr, y.Pointer(), workspace.Pointer(), C.size_t(workSpaceSizeInBytes), dwDesc.internal, dw.Pointer(), reserveSpace.Pointer(), C.size_t(reserveSpaceSizeInBytes)))
}

// CTCLoss returns the ctc costs and gradients, given the probabilities and labels.
func (co *Context) CTCLoss(probsDesc *TensorDescriptor, probs Memory, labels []int, labelLengths []int, inputLengths []int, costs Memory, gradientsDesc *TensorDescriptor, gradients Memory, algo CTCLossAlgo, ctcLossDesc *CTCLoss, workspace Memory, workSpaceSizeInBytes uintptr) error {
	// DOUBLECHECK: "cudnnCTCLoss" returns Memory type in Parameter 8
	labelsPtr, labelsPtrManaged := ints2CIntPtr(labels)
	defer returnManaged(labelsPtrManaged)
	labelLengthsPtr, labelLengthsPtrManaged := ints2CIntPtr(labelLengths)
	defer returnManaged(labelLengthsPtrManaged)
	inputLengthsPtr, inputLengthsPtrManaged := ints2CIntPtr(inputLengths)
	defer returnManaged(inputLengthsPtrManaged)

	// call cudnnCTCLoss
	return result(C.cudnnCTCLoss(co.internal, probsDesc.internal, probs.Pointer(), labelsPtr, labelLengthsPtr, inputLengthsPtr, costs.Pointer(), gradientsDesc.internal, gradients.Pointer(), algo.C(), ctcLossDesc.internal, workspace.Pointer(), C.size_t(workSpaceSizeInBytes)))
}

// // Derives a secondary tensor descriptor for BatchNormalization scale, invVariance, bnBias, bnScale subtensors from the layer's x data descriptor. Use the tensor descriptor produced by this function as the bnScaleBiasMeanVarDesc and bnScaleBiasDiffDesc parameters in Spatial and Per-Activation Batch Normalization forward and backward functions. Resulting dimensions will be 1xC(x1)x1x1 for BATCHNORM_MODE_SPATIAL and 1xC(xD)xHxW for BATCHNORM_MODE_PER_ACTIVATION (parentheses for 5D). For HALF input data type the resulting tensor descriptor will have a FLOAT type. For other data types it will have the same type as the input data.
// func (te *TensorDescriptor) DeriveBNTensorDescriptor(xDesc *TensorDescriptor, mode BatchNormMode) (derivedBnDesc *TensorDescriptor, err error) {
// 	// TODO
// 	// call cudnnDeriveBNTensorDescriptor
// 	err = result(C.cudnnDeriveBNTensorDescriptor(te.internal, xDesc.internal, mode.C()))
// 	return
// }

// DropoutGetReserveSpaceSize is used to query the amount of reserve needed to run dropout with the input dimensions given by xDesc. The same reserve space is expected to be passed to cudnnDropoutForward and cudnnDropoutBackward, and its contents is expected to remain unchanged between cudnnDropoutForward and cudnnDropoutBackward calls.
func (te *TensorDescriptor) DropoutGetReserveSpaceSize() (sizeInBytes uintptr, err error) {
	var sizeInBytesC C.size_t
	// call cudnnDropoutGetReserveSpaceSize
	err = result(C.cudnnDropoutGetReserveSpaceSize(te.internal, &sizeInBytesC))
	sizeInBytes = uintptr(sizeInBytesC)
	return
}

