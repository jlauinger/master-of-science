{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grep_df = pd.read_csv('/root/data/lexical/grep_findings_0_499.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         var CacheLineSize uintptr = CacheLinePadSize\\n\n",
       "1      \\toffsetX86HasSSE2   = unsafe.Offsetof(cpu.X86...\n",
       "2      \\toffsetX86HasSSE42  = unsafe.Offsetof(cpu.X86...\n",
       "3      \\toffsetX86HasAVX2   = unsafe.Offsetof(cpu.X86...\n",
       "4      \\toffsetX86HasPOPCNT = unsafe.Offsetof(cpu.X86...\n",
       "                             ...                        \n",
       "995                \\t\\t\\t\\t*(*unsafe.Pointer)(k) = nil\\n\n",
       "996    \\t\\t\\te := add(unsafe.Pointer(b), dataOffset+b...\n",
       "997    \\t\\t\\te := add(unsafe.Pointer(b), dataOffset+b...\n",
       "998    \\t\\t\\te := add(unsafe.Pointer(b), dataOffset+b...\n",
       "999                \\t\\t\\t\\t*(*unsafe.Pointer)(e) = nil\\n\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippets = grep_df['text'][:1000]\n",
    "snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_fd = nltk.FreqDist(set.union(*[tokenize(snippet) for snippet in snippets]))\n",
    "all_tokens = [token for token, _ in token_fd.most_common(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(snippet):\n",
    "    return set(list(re.split('[\\s\\(\\)]+', snippet)))\n",
    "\n",
    "def extract_features(snippet, all_tokens):\n",
    "    tokens = tokenize(snippet)\n",
    "    return {\"contains_{}\".format(token): token in tokens for token in all_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [extract_features(snippet, all_tokens) for snippet in snippets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'h',\n",
       " 'dataOffset+inserti*8',\n",
       " 'buckets',\n",
       " '_cgo_mmap',\n",
       " 'integer,',\n",
       " 'datap.edata',\n",
       " 'err',\n",
       " 'selectnbrecv',\n",
       " 'int',\n",
       " 'mallocgc',\n",
       " 'sp.str,',\n",
       " 'base',\n",
       " 'named',\n",
       " 'ret',\n",
       " 'dumpobj',\n",
       " '*arraytype',\n",
       " 'strhash',\n",
       " 'reflect_chansend',\n",
       " 'selectnbsend',\n",
       " 'frame',\n",
       " '&bv,',\n",
       " 'oldbucket+newbit',\n",
       " 'allocs,',\n",
       " 'may',\n",
       " 'cpuprof.extra[i]',\n",
       " 'local_scan',\n",
       " 'mapaccessK',\n",
       " 'memhash',\n",
       " 'memEnd',\n",
       " 'uintptr',\n",
       " 'bucketMask',\n",
       " 'dumpint',\n",
       " \"uintptr's\",\n",
       " 'new',\n",
       " 'gp._panic',\n",
       " 'handles',\n",
       " 'dataOffset+i*8',\n",
       " 'chanLock',\n",
       " 'stack',\n",
       " 'Loadp',\n",
       " 'inheap',\n",
       " 'uint64',\n",
       " 'd',\n",
       " 'old',\n",
       " 'return',\n",
       " 'minLegalPointer',\n",
       " 'datap.bss',\n",
       " 'or',\n",
       " 'callCgoMmap']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = DictVectorizer(sparse=False)\n",
    "\n",
    "X = v.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = KMeans(init='k-means++', n_clusters=8).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_string(tokens):\n",
    "    for key, value in tokens.items():\n",
    "        if value > 0.001:\n",
    "            print(key[len(\"contains_\"):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new\n",
      "old\n",
      "return\n",
      "uintptr\n"
     ]
    }
   ],
   "source": [
    "vector_to_string(v.inverse_transform(cls.cluster_centers_)[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
