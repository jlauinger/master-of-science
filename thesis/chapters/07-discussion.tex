%% ---------------------------------------------------------------------------------------------------------------------

\chapter{Discussion}\label{ch:discussion}

This chapter puts the results of this thesis in context and discusses the findings.
First, the dangers and practical exploitability of real-world Go applications due to usage of the \unsafe{} API are
elaborated.
Then, the patches that were sent to open-source code maintainers  are described in detail and suggestions towards a
world with safer usage practices of \unsafe{} code are given.
Finally, threats to validity and future work are presented.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Practical Exploitability of Unsafe Code}\label{sec:discussion:exploitability}

This thesis took a deep look into the \unsafe{} API of the Go programming language.
It was shown that it is effectively used by almost all of the \projsAnalyzed{} top-starred open-source projects
(\percentageUnsafeTransitiveWithDependencies{}) either directly or by including \unsafe{} usages through third-party
dependencies.
While there are many legitimate use cases for \unsafe{} code, such as efficient conversions between otherwise
incompatible types without allocating additional memory or accessing the foreign function interface (\acrshort{FFI}),
a thorough manual study also showed that there are dangers and possible vulnerabilities that can come from it.
While the data collected when creating the labeled data set of annotated \unsafe{} usage examples shows that the
majority of the usages are safe and legitimate, there were also several bugs that could lead to severe vulnerabilities.

A contribution of this thesis is novel evidence of possible misuses of the \unsafe{} \acrshort{API} with concrete proof
showing how a vulnerability is introduced.
The changes needed to avoid the misuses are often minor and subtle, which underlines the fact that \unsafe{} is a
fragile and dangerous feature of the Go programming language.
It is complicated to understand the dangers a given piece of code has and could have in the future, especially if there
is interaction with other parts of the code base and other developers.
If a bug is introduced, it can easily slip through code review and be part of a zero day exploit some time later.
The bugs that were found during the course of this work, and to which I submitted patches as described in the next
section, may seem few and minor at first glance, but it only takes one \textit{use-after-free} bug at a critical
position to open up the possibility of a major remote code execution attack.

The general direction that programming languages like Go or Rust take is the right one.
By enforcing a strict safety net in most cases and still allowing escape hatches to circumvent these measures when it is
absolutely necessary, they combine the best of two worlds.
In most of the code base, buffer overflows, race conditions etc. are prevented at the small cost of a slightly more
rigid coding workflow and developer training.
There is however still the option of complete flexibility and total control over the memory if it should be needed.
This allows organizations to focus auditing and review efforts on the code parts that use the \unsafe{} \acrshort{API},
which is a fraction of the total code.
Therefore, the code that really matters with respect to a security perspective can be reviewed with much more detail
without increasing development and maintenance costs.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Patching Open-Source Projects}\label{sec:discussion:patches}

In the process of analyzing \unsafe{} usages in real-world Go code, and using the novel static analysis tool
\toolSafer{}, I found more than \numberBugsFixedRounded{} unsafe-related bugs that can lead to security
vulnerabilities.
Most of them are instances of incorrect constructions of slice header values, which are used with in-place conversions
between slices of different types.
These can cause the \textit{use-after-free} vulnerabilities due to the garbage collector freeing a value that is still
in use or an error in the escape analysis causing a value to be placed on the stack incorrectly, as described in
Sections~\ref{subsec:unsafe-security-problems:slice-casts:gc-race}
and~\ref{subsec:unsafe-security-problems:slice-casts:escape-analysis}.
Furthermore, there is the bug causing incorrect length information in a slice in the \goFuse{} library as described in
Section~\ref{subsec:unsafe-security-problems:slice-casts:incorrect-length}.

I submitted \numberPRs{} pull requests with patches to these bugs to the authors of the affected libraries on
\github{}.
This is a public disclosure procedure, although the bugs have not been announced on any news pages.
Given that there are currently no actual exploits that use the bugs to inject code or leak data, this was a good choice
compared to other procedures like a responsible disclosure for example.
Submitting \github{} pull requests allows the code authors to easily merge the necessary changes.

\input{assets/tables/chapter7/submitted-pull-requests.tex}

Table~\ref{tbl:pull-requests} lists the pull requests with their respective \github{} project.
The Popularity column indicates how many projects in the data set of the top \projsTotal{} most popular Go projects use
the respective library, showing the impact of bugs.
For the bug in \textit{mailu/easyjson}, there was already an existing open pull request.
So far \numberPRsMerged{} of the pull requests have been reviewed, acknowledged, and accepted by the authors.
The remaining were not rejected either, but received no attention due to a generally high volume of open pull requests
in the project.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Suggestions for Safer Go Code}\label{sec:discussion:safer-go-code}

Usages of \unsafe{} that get imported through third-party dependencies are dangerous because they can be hidden at first
glance, but still get compiled into the resulting application binary.
On top of the fact that external dependencies tend to get updated rather late if at all, as was discussed in
Section~\ref{sec:related-work:dependency-issues}, there is now also the possibility that there is simply nobody even
aware of the potential danger.
The novel tool \toolGeiger{} is a large step in the journey of improving this situation, as it allows to quickly and
effectively differentiate the libraries that need auditing from those that do not.
An effective next step would be to use this information even before deciding which library to use.
If there are multiple external libraries that achieve the same goal, choosing which one to use should incorporate the
data about how many \unsafe{} usages each library contains, if any.
Libraries with less \unsafe{} code should be preferred over those with much.
It would be beneficial to contribute towards a situation where library maintainers use the number of \unsafe{} usages
in their library as a feature or part of its advertisement.
Similar to code quality report badges on the \github{} repository of the project, there could be a badge showing if the
library uses any \unsafe{} code, and if it does how much.

Since the study data for this thesis has been collected, the most recent Go release \checkNum{1.15} from
\checkNum{August 2020} has enabled additional static checking of \textit{unsafe.Pointer} usages with the
\textit{-d=checkptr} compiler flag~\footnote{\url{https://golang.org/doc/go1.14\#compiler}}.
The development of the new check had been started with Go release \checkNum{1.14} already.
It checks that the alignment of the target type matches the alignment of the pointer when converting unsafe pointers to
an arbitrary type.
Furthermore, the result of pointer arithmetic can not be a completely arbitrary heap value anymore, instead at least one
argument of the arithmetic expression must already be a pointer into the resulting value if it is a heap value.
Both checks prevent some misuses of \unsafe{} that can occur if the developer took a false assumption over the types
involved in a conversion, and therefore they are a valuable step towards a safer Go with \unsafe{}.
However, the new check can not find the misuses that are detected by \toolSafer{}, which underlines the need of
continuous improvement of the developer tools and continued awareness of potentially still unknown dangers with the use
of \unsafe{}.

Finally, some \unsafe{} usages in the analyzed open-source projects were necessary to achieve functionality that could
have been implemented with generics too, if they were available in Go.
Generics are in fact one of the most widely requested features for the Go programming language, with \checkNum{79\%} of
participants in the \checkNum{2019} Go Developer Survey~\footnote{\url{https://blog.golang.org/survey2019-results}}
stating that they think it is a critical missing feature.
Since generics have now been officially announced~\footnote{\url{https://blog.golang.org/go2-next-steps}} for the
upcoming Go release \checkNum{2.0}, these \unsafe{} usages can then be replaced by the new generics support.
Similarly, other language improvements such as a new foreign function interface could make other usages of \unsafe{}
which are necessary at the moment obsolete, thus decreasing the room for errors made by the developers and therefore
increasing security and safety.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Threats to Validity}\label{sec:discussion:threats-to-validity}

This section discusses potential threats to validity to the empirical study of \unsafe{} usages in popular open-source
Go projects.
Internal threats concern the quality of execution for the study.
They include a bias towards bigger projects because with a higher number of lines of code, they could be
overrepresented in the data set of manually labeled \unsafe{} usages.
Next, we only considered projects that use the Go module system and could compile on our machines.

On the other hand, external threats to validity concern the ability to generalize the study results to new data.
They include a bias towards certain projects as well, as the distribution of \unsafe{} usages might be correlated to the
project size, activity or number of contributors, or others.
Furthermore, when analyzing \unsafe{} code examples for security, we might have excluded usage patterns that are
uncommon in the top \projsTotal{} most popular projects, but frequent in projects of a specific problem domain.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Future Work}\label{sec:discussion:future-work}

Based on the contributions of this thesis, future research might look into the following areas.
First, the novel data set of manually labeled \unsafe{} usages, containing code samples along labels on what is being
done and for what purpose, could be used as a training and verification data set in machine learning applications.
It could be used for example to evaluate possible future static analysis tools with a focus on \unsafe{} Go code,
to train an automated classification tool that could possibly predict the danger of new \unsafe{} code patterns.
Furthermore, it can be used as a seed for further studies on the design and adoption of \unsafe{} APIs not only in Go
but also across other languages.

Next, the novel developer tools \toolGeiger{} and \toolSafer{} presented in this thesis could be integrated into
developer \acrshort{IDE}s.
While the current command line interface works well for the initial development of the tools, is a preferred user
interface for some developers anyway, and is especially suitable to be used as part of a continuous integration
(\acrshort{CI}) automation, an \acrshort{IDE} integration has the benefit of being able to unify the display of warnings
with the editor that the developer uses to fix them.
For example, \toolSafer{} warnings can be displayed next to the affected line directly in the editor, and the code that
violates the safety rules could be highlighted to effectively draw the attention of the developer.
As described in Section~\ref{sec:related-work:static-code-analysis}, this can lead to a higher fraction of warnings
actually being resolved.
Such an \acrshort{IDE} integration could be implemented using the language server
protocol~\footnote{\url{https://langserver.org/}}, as this allows for easy compatibility with most \acrshort{IDE}s
without the need to develop individual plugins for each of them.

Finally, future work could integrate the static code analysis tool \toolSafer{} into \toolVet{}, the official linter
for Go code that ships as part of the standard compiler toolchain.
This would be fairly easy because \toolSafer{} is build using the \toolVet{} infrastructure.
Therefore, the analysis passes provided by \toolSafer{} could directly be added to the set of analysis shipped with
\toolVet{}.
Achieving this would reduce the effort to use \toolSafer{} a lot and could therefore increase the adoption of the tool,
even only passively as part of using \toolVet{} with a \acrshort{CI} workflow, leading to safer Go applications overall.
