%% ---------------------------------------------------------------------------------------------------------------------

\chapter{Discussion}\label{ch:discussion}

This chapter discusses the results and findings of this thesis.
First, the dangers and practical exploitability of real-world Go applications due to usage of the \unsafe{} API are
elaborated.
Then, the patches that were sent to open-source code maintainers  are described in detail and suggestions towards a
world with safer usage practices of \unsafe{} code are given.
Finally, threats to validity and future work are presented.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Practical Exploitability of Unsafe Code}\label{sec:discussion:exploitability}

This thesis took a deep look into the \unsafe{} API of the Go programming language.
It was shown that it is effectively used by almost all of the \projsAnalyzed{} top-starred open-source projects
(\percentageUnsafeTransitiveWithDependencies{}) either directly or by including \unsafe{} usages through third-party
dependencies.
While there are many legitimate use cases for \unsafe{} code, such as efficient conversions between otherwise
incompatible types without allocating additional memory or accessing the foreign function interface (\acrshort{FFI}),
a thorough manual study also showed that there are dangers and possible vulnerabilities that can come from it.
While the data collected when creating the labeled data set of annotated \unsafe{} usage examples shows that the
majority of the usages are safe and legitimate, there were also several bugs that could lead to severe vulnerabilities.

A contribution of this thesis is novel evidence of possible misuses of the \unsafe{} \acrshort{API} with concrete proof
showing how a vulnerability is introduced.
The changes needed to avoid the misuses are often minor and subtle, which underlines the fact that \unsafe{} is a
fragile and dangerous feature of the Go programming language.
It is complicated to understand the dangers a given piece of code has and could have in the future, especially if there
is interaction with other parts of the code base and other developers.
If a bug is introduced, it can easily slip through code review and be part of a zero day exploit some time later.
The bugs that were found during the course of this work, and to which I submitted patches as described in the next
section, may seem few and minor at first glance, but it only takes one \textit{use-after-free} bug at a critical
position to open up the possibility of a major remote code execution attack.

The general direction that programming languages like Go or Rust take is the right one.
By enforcing a strict safety net in most cases and still allowing escape hatches to circumvent these measures when it is
absolutely necessary, they combine the best of two worlds.
In most of the code base, buffer overflows, race conditions etc. are prevented at the small cost of a slightly more
rigid coding workflow and developer training.
Still, there is the option of complete flexibility and total control over the memory if it should be needed.
This allows organizations to focus auditing and review efforts on the code parts that use the \unsafe{} \acrshort{API},
which is a fraction of the total code.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Patching Open-Source Projects}\label{sec:discussion:patches}

In the process of analyzing \unsafe{} usages in real-world Go code, and using the novel static analysis tool
\toolSafer{}, I found \numberBugsFixed{} unsafe-related bugs that can lead to security vulnerabilities.
Most of them (\checkNum{63}) are instances of incorrect constructions of slice header values, which are used with
in-place conversions between slices of different types.
These can cause the \textit{use-after-free} vulnerabilities due to the garbage collector freeing a value that is still
in use or an error in the escape analysis causing a value to be placed on the stack incorrectly, as described in
Sections~\ref{subsec:unsafe-security-problems:slice-casts:gc-race}
and~\ref{subsec:unsafe-security-problems:slice-casts:escape-analysis}.
Furthermore, there is the bug causing incorrect length information in a slice in the \goFuse{} library as described in
Section~\ref{subsec:unsafe-security-problems:slice-casts:incorrect-length}.

I submitted \numberPRs{} pull requests with patches to these bugs to the authors of the affected libraries on
\github{}.
These pull requests contain fixes to one or more bugs, with a total number of \numberBugsFixed{} resolved bugs.
Furthermore, \checkNum{one} additional pull request already existed.
They are listed in Table~\ref{tbl:pull-requests} along with their respective \github{} projects.
The Popularity column indicates how many projects in the data set of the top \projsTotal{} most popular Go projects use
the respective library, showing the impact of bugs.
Furthermore, the table indicates which of the pull requests have been merged so far, and how many bugs they contain
individually.

\input{assets/tables/chapter7/submitted-pull-requests.tex}

This is a public disclosure procedure, although the bugs have not been announced on any news pages.
Given that there are currently no actual exploits that use the bugs to inject code or leak data, this was a good choice
compared to other procedures like a responsible disclosure, for example.
Submitting \github{} pull requests allows the code authors to easily merge the necessary changes.
For the bug in \textit{mailu/easyjson}, there was already an existing open pull request.
So far \numberPRsMerged{} of the pull requests have been reviewed, acknowledged, and accepted by the authors.
The remaining were not rejected either, but received no attention due to a generally high volume of open pull requests
in the project.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Suggestions for Safer Go Code}\label{sec:discussion:safer-go-code}

Usages of \unsafe{} that get imported through third-party dependencies are dangerous because they can be hidden at first
glance, but still get compiled into the resulting application binary.
On top of the fact that external dependencies tend to get updated rather late if at all, as was discussed in
Section~\ref{sec:related-work:dependency-issues}, there is now also the possibility that there is simply nobody even
aware of the potential danger.
The novel tool \toolGeiger{} is a large step in the journey of improving this situation, as it allows to quickly and
effectively differentiate the libraries that need auditing from those that do not.
An effective next step would be to use this information even before deciding which library to use.
If there are multiple external libraries that achieve the same goal, choosing which one to use should incorporate the
data about how many \unsafe{} usages each library contains, if any \todo{check with work by Sarah Nadi}.
Libraries with less \unsafe{} code should be preferred over those with much.
It would be beneficial to contribute towards a situation where library maintainers use the number of \unsafe{} usages
in their library as a feature or part of its advertisement.
Similar to code quality report badges on the \github{} repository of the project, there could be a badge showing if the
library uses any \unsafe{} code, and if it does how much.
However, it is important to remember that the number of \unsafe{} usages is not itself an indicator for the safety of
a library or project.
First, security problems can also be introduced in code that does not use \unsafe{} at all.
Second, there could be many well audited \unsafe{} usages in one project, and a single one that causes a vulnerability
in another one.
Although the number of \unsafe{} usages in the second project is smaller, it is much less secure.

Since the study data for this thesis has been collected, the most recent Go release \checkNum{1.15} from
\checkNum{August 2020} has enabled additional static checking of \textit{unsafe.Pointer} usages with the
\textit{-d=checkptr} compiler flag\footnote{\url{https://golang.org/doc/go1.14\#compiler}}.
The development of the new check had been started with Go release \checkNum{1.14} already.
It checks that the alignment of the target type matches the alignment of the pointer when converting unsafe pointers to
an arbitrary type.
Furthermore, the result of pointer arithmetic can not be a completely arbitrary heap value anymore, instead at least one
argument of the arithmetic expression must already be a pointer into the resulting value if it is a heap value.
Both checks prevent some misuses of \unsafe{} that can occur if the developer took a false assumption over the types
involved in a conversion, and therefore they are a valuable step towards a safer Go with \unsafe{}.
However, the new check can not find the misuses that are detected by \toolSafer{}, which underlines the need of
continuous improvement of the developer tools and continued awareness of potentially still unknown dangers with the use
of \unsafe{}.
\todo{which of the problems described in Chapter 3 are solved with this new feature?}

Finally, some \unsafe{} usages in the analyzed open-source projects were necessary to achieve functionality that could
have been implemented with generics too, if they were available in Go.
Generics are in fact one of the most widely requested features for the Go programming language, with \checkNum{79\%} of
participants in the \checkNum{2019} Go Developer Survey\footnote{\url{https://blog.golang.org/survey2019-results}}
stating that they think it is a critical missing feature.
Since generics have now been officially announced\footnote{\url{https://blog.golang.org/go2-next-steps}} for the
upcoming Go release \checkNum{2.0}, these \unsafe{} usages can then be replaced by the new generics support.
Similarly, other language improvements such as a new foreign function interface could make other usages of \unsafe{}
which are necessary at the moment obsolete, thus decreasing the room for errors made by the developers and therefore
increasing security and safety.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Threats to Validity}\label{sec:discussion:threats-to-validity}

This section discusses potential threats to the validity of this work.
Internal threats concern the quality of execution and whether any results could be explained by other factors that were
not covered in this thesis.
First,


On the other hand, external threats to validity concern the ability to generalize the study results to new data.


 - labeled data set and study: bias towards bigger projects (external)
 - study: bias towards projects with module support (external)
 - unsafe code patterns: potential bias excluding specific problem domains (external)
 - study: unsafe might be located in dead code (internal)
 - unsafe code patterns: manual analysis might have left out some (internal)


This section discusses potential threats to validity to the empirical study of \unsafe{} usages in popular open-source
Go projects.

They include a bias towards bigger projects because with a higher number of lines of code, they could be
overrepresented in the data set of manually labeled \unsafe{} usages \todo{explain how this is mitigated}.
Next, we only considered projects that use the Go module system and would compile on our machines.

On the other hand, external threats to validity concern the ability to generalize the study results to new data.
They include a bias towards certain projects as well, as the distribution of \unsafe{} usages might be correlated to the
project size, activity or number of contributors, or others.
Furthermore, when analyzing \unsafe{} code examples for security, we might have excluded usage patterns that are
uncommon in the top \projsTotal{} most popular projects, but frequent in projects of a specific problem domain.
\todo{what are the differences and consequences in such projects?}


%% ---------------------------------------------------------------------------------------------------------------------

\section{Future Work}\label{sec:discussion:future-work}

Based on the contributions of this thesis, future work might look into the following areas.
The novel data set of manually labeled \unsafe{} usages can be used for interesting further research.
First, the code samples in the \textit{efficiency} class do not strictly require the use of \unsafe{}, but should increase the
performance of the code.
Future work could quantify by how much \unsafe{} actually increases the efficiency compared to using other, memory-safe
language features of Go.
If the improvement is small, \unsafe{} would pose an unnecessary risk that could be avoided.
Especially, a comparison with performance improvements of new Go compiler releases would be interesting to see if
simply waiting for a new version of the compiler can provide more efficient program binaries than \unsafe{} does.
Furthermore, future work could evaluate the possibility of automatically replacing such \unsafe{} usages with safe
language constructs.
Finally, the labeled data set could be used as a training and verification data set in machine learning applications.
For example, an automated classification tool that predicts the purpose and danger of unseen \unsafe{} code patterns
could be built.
This would be valuable both for security analysts to conduct a large-scale study of \unsafe{} usages in thousands of
projects, and for software engineers to highlight particularly dangerous usages in the findings of \toolGeiger{}, as
well as ones that can be replaced with new language features.

Next, future research could focus on verification techniques for \unsafe{} Go code, such as annotations for
contracts or invariants that formalize assertions about control and data flow.
For example, \unsafe{} code that creates implicitly read-only values could be formally declared immutable, such that
a verifier can detect invalid accesses to the value.
A static verification would probably be preferable over a dynamic one, because the additional runtime overhead could
potentially outweigh the efficiency improvements of using \unsafe{} in the first place.

Furthermore, establishing a public documentation of good and bad usage examples of the Go \unsafe{} \acrshort{API} could
help developers avoid common mistakes.
For insecure usages, it could provide an explanation of the potential vulnerability, as well as a suggestion for a
secure alternative.
Similar to \toolSafer{}, a linter could be developed to identify harmless usages of \unsafe{}, which could then
automatically be flagged safe and thus be excluded from manual review.

Finally, the novel tools \toolGeiger{} and \toolSafer{} presented in this thesis could be integrated into developer
environments (\acrshort{IDE}s).
This would have the benefit of displaying warnings within the editor that is used to fix them.
As described in Section~\ref{sec:related-work:static-code-analysis}, this can lead to a higher fraction of warnings
actually being resolved.

%While the current command line interface works well for the initial development of the tools, and is especially suitable
%to be used as part of a continuous integration automation, an \acrshort{IDE} integration has the benefit of being able
%to unify the display of warnings with the editor that the developer uses to fix them.
%For example, \toolSafer{} warnings can be displayed next to the affected line directly in the editor, and the code that
%violates the safety rules could be highlighted to effectively draw the attention of the developer.
%As described in Section~\ref{sec:related-work:static-code-analysis}, this can lead to a higher fraction of warnings
%actually being resolved.
%Such an \acrshort{IDE} integration could be implemented using the language server
%protocol\footnote{\url{https://langserver.org/}}, as this allows for easy compatibility with most \acrshort{IDE}s
%without the need to develop individual plugins for each of them.