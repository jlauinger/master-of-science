%% ---------------------------------------------------------------------------------------------------------------------

\chapter{\textit{go-safer}: Detecting Unsafe Misuses}\label{ch:go-safer}

Another major contribution of this thesis is the development of \toolSafer{}, a \toolVet{}-style, open-source linter
tool with a focus on the \unsafe{} \acrshort{API} in Go.
It can identify some of the unsafe code patterns described in Chapter~\ref{ch:unsafe-security-problems} and thus help
developers to write safer code.
This chapter describes the design and implementation of \toolSafer{}, as well as an evaluation of its effectiveness both
using the labeled data set of \unsafe{} usages presented in the previous chapter and a manual analysis of \checkNum{six}
open-source Go packages.

\input{assets/figures/chapter5/outline5.tex}


%% ---------------------------------------------------------------------------------------------------------------------

\section{Design}\label{sec:go-safer:design}

The \toolSafer{} static analysis tool is designed as a linter to identify two misuses of the \unsafe{} \acrshort{API}
that were previously undetected with existing tools such as \toolVet{} and \toolGosec{}.
The selection of the code patterns that are detected is based on the \unsafe{} usage examples identified using
\toolGeiger{} in popular open-source Go projects as described in Chapter~\ref{ch:go-geiger}, as well as the manual
analysis of possible vulnerabilities related to the use of the \unsafe{} \acrshort{API} presented in
Chapter~\ref{ch:unsafe-security-problems}.
The first is the incorrect conversion pattern between slices and strings by creating their header structures as
composite literals as described in Section~\ref{subsec:unsafe-security-problems:slice-casts:gc-race}.
Listing~\ref{lst:go-safer-sliceheader-pass} shows example code that uses this unsafe pattern.

\input{assets/listings/chapter5/go-safer-sliceheader-pass.tex}

In addition to composite literals of type \textit{reflect.SliceHeader} and \textit{reflect.StringHeader}, \toolSafer{}
analyzes accesses to fields of existing instances of these types.
When they are detected, the tool checks whether the given header structure instance was derived by cast from a real
slice or string.
If that is not the case or can not be statically inferred, for example because the header value is given as a function
parameter or return type, or there is only a declaration of the variable and type without an initialization, then the
field access is treated as potentially unsafe and \toolSafer{} generates a warning.
\toolSafer{} parses the packages to acquire the abstract syntax trees (\acrshort{AST}) for all files.
This allows the tool to run analysis steps that are independent from concrete names in the source code.
If the slice or string header types are renamed to a different type name in the source code, then field accesses to and
composite literals of the new type name are recognized just like the original types.

The second misuse that \toolSafer{} detects is a direct conversion between struct types containing incompatible types
with architecture-dependent sizes as described in
Section~\ref{subsec:unsafe-security-problems:slice-casts:escape-analysis}.
Listing~\ref{go-safer-structcast-pass} is an example of such code.

\input{assets/listings/chapter5/go-safer-structcast-pass.tex}

To identifiy this misuse, \toolSafer{} finds direct conversions between structures using the \textit{unsafe.Pointer}
type.
Then, the source and target types are compared.
If they contain a different amount of fields of the types \textit{int}, \textit{uint}, or \textit{uintptr}, a warning
is issued.
These are the types with architecture-dependent sizes available in Go.

The source code and documentation of \toolSafer{} is available on
\github{}\footnote{\url{https://github.com/jlauinger/go-safer}}.
It can be installed using the standard Go \acrshort{CLI} tool and is run with the source code packages that should be
checked as parameters.
For example, to check a local package run \textit{go-safer ./my/package}.
There is no limitation on the number of packages that can be supplied as parameters.
Figure~\ref{go-safer-screenshot} shows a screenshot of \toolSafer{} containing a few warnings about insecure slice
conversions.

\input{assets/images/chapter5/go-safer-screenshot.tex}

\toolSafer{} is based on the same foundation as \toolVet{}, therefore it supports the same command line arguments and
options.
These include amongst others the option to include a context of adjacent source code lines for each warning in the
output, or change the output format to machine-readable JSON instead of the standard output, which is designed to be
read by humans.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Implementation}\label{sec:go-safer:implementation}

As mentioned in the last section, \toolSafer{} is built using the Go analysis infrastructure that is available as part
of \toolVet{}.
This allows to compose analysis steps as modular and reusable parts, which are called \textit{passes}.
Each analysis pass is run on the source code packages under analysis as a unit.
It can depend on the results of other analysis passes, which are then run before it and hand the results over to it.
The passes and their relations must form a directed acyclic graph, and the analyis infrastructure code determines the
optimal execution order and parallelism.
There are two novel analysis passes in \toolSafer{}, the \textit{sliceheader} and the \textit{structcast} pass.
Figure~\ref{fig:go-safer-architecture} shows an overview of this architecture.

\input{assets/figures/chapter5/go-safer-architecture.tex}

Parsing the source code of the packages under analysis is done using the same code as \toolVet{} uses, in fact that code
is required as a dependency for \toolSafer{}.
Then, the abstract syntax tree (\acrshort{AST}) and control flow graph (\acrshort{CFG}) of the sources are built using
existing analysis passes which the novel \toolSafer{} passes depend upon.
After all analysis passes have run, the results are also presented to the user by the same code used in \toolVet{}.
This composition using many existing parts allows to keep the required new code to a minimum, reuses well-tested pieces
of code, and allows to integrate the new \toolSafer{} features into a familiar workflow.

The \textit{sliceheader} analysis pass first receives the \acrshort{AST} and filters it for composite literals and
assignment statements.
These are given by \textit{ast.CompositeLit} and \textit{ast.AssignStmt} nodes.
Recursively going down the \textit{AST} even after a composite literal has been found ensures that \toolSafer{} also
detects such literals that are part of a bigger structure type that contains a slice header as one of its fields.
Then, the type of either the composite literal or the assignment receiver is checked.
For assignments, this is done by looking up the left hand side identifier in a typing table provided by the parser.
Since Go supports multiple assignments in one statement, there can be multiple variables on the left hand side.
In this case, \toolSafer{} checks all of them to see if any meets the conditions to trigger a warning.
To check whether the type matches either \textit{reflect.StringHeader} or \textit{reflect.SliceHeader}, the given type
is checked for assignability to the underlying structure of the header types.
This structure, as illustrated in Figure~\ref{fig:go-safer-architecture}, is one \textit{uintptr} fields and then one
or two \textit{int} fields.
Comparing to the structure instead of the name of the type makes it possible to detect type aliases to the header types
which might exist.
For example, when there is a \textit{type CustomHeader reflect.SliceHeader} definition, then \toolSafer{} will also
detect composite literals of type \textit{CustomHeader}.
A composite literal of a header type is already enough to issue a warning, but for assignments \toolSafer{} needs to
check whether the receiver variable is a slice or string header that was created by conversion from a real slice or
string.
To do this, the \acrshort{AST} assignment node is located within the \acrshort{CFG}.
Then, going backwards in the \acrshort{CFG}, the first node that assigns the value of the receiver variable is found.
This node is the effective value of the slice or string header structure at the time of the assignment under
investigation.
Finally, \toolSafer{} checks whether the right hand side value of the statement defining that value is a conversion
from an actual slice or string value.
It has to be a cast through an \textit{unsafe.Pointer} value for that.
If this is the case, then the assignment is legitimate and \toolSafer{} does not print a warning.
However, if the variable is not derived by a conversion from a slice or string, or no \acrshort{CFG} node defining the
variable can be found, then a warning is issued.
The last case is possible for example if the slice or string header is passed in as a function parameter, because then
its value can not be statically inferred with the Go analysis framework.

The \textit{structcast} pass also uses the \acrshort{AST} to find cast operations.
These are represented in the \acrshort{AST} in the same way as function calls are, so the tree is filtered for
\textit{CallExpr} nodes.
If there is a cast from some structure type to \textit{unsafe.Pointer} and then further to another structure type, then
these source and target types are analyzed.
These types can again be fetched from a type lookup table provided by the parser.
For both of them, \toolSafer{} counts the number of fields that have the types \textit{int}, \textit{uint}, and
\textit{uintptr}.
These \checkNum{three} basic types are the ones available in Go that have different sizes on varying architectures.
For example, \textit{int} is \checkNum{eight} bytes on the \textit{amd64} architecture, but only \checkNum{four} bytes
on \textit{i386}.
If the counts mismatch, then the direct cast using the \unsafe{} \acrshort{API} will likely break on some architectures,
and \toolSafer{} generates a warning.

A set of automated tests verifies that \toolSafer{} works as expected.
These tests also use the framework provided by the Go analysis infrastructure, which allows tests to be written as
individual source packages where expected warnings are given as line comments in the respective lines.
On the other hand, lines that must not trigger any warnings can either have no comment or an explit \textit{ok} comment.
This allows a fast and effective composition of new test cases.
At the same time, the test cases provide formal documentation about positive and negative examples for the code patterns
detected by \toolSafer{}.


%% ---------------------------------------------------------------------------------------------------------------------

\section{Evaluation}\label{sec:go-safer:evaluation}

In order to make a valuable contribution to the safety of Go programs and at the same time be an effective tool for
developers, it is important that \toolSafer{} can find actual bugs in real-world Go projects, and at the same time has
a low rate of false positives and false negatives.
False negatives would mean that the tool misses incorrect and therefore potentially vulnerable usages of the \unsafe{}
\acrshort{API}.
On the other hand, a high rate of false positives would mean that it generates many warnings that are not related to
any programming errors.
This would require developers to manually review the findings and dismiss many of them, which decreases the value of
\toolSafer{} significantly.
First, developers could lose trust in the tool and refuse using it with their regular development workflows.
Second, false positives make it hard to integrate \toolSafer{} with automated \acrshort{CI} processes, because the build
would fail without there being a real problem.

To demonstrate that \toolSafer{} is capable of findings actual bugs while having an acceptable rate of both false
positives and negatives, its performance is evaluated in two different ways.
One of them uses the novel data set of labeled \unsafe{} usages, which was presented in
Section~\ref{sec:go-geiger:labeled-dataset}.
The second one is done by manually analyzing \checkNum{six} selected open-source Go packages from different projects and
then comparing the results to the output of \toolSafer{}.
As shown in the following sections, \toolSafer{} is able to achieve both high precision and accuracy in the two
evaluations.
Finally, the performance is compared to the existing static analysis tools \toolVet{} and \toolGosec{}.


%% ---------------------------------------------------------------------------------------------------------------------

\subsection{Labeled Usages}\label{subsec:go-safer:evaluation:labeled-usages}

To evaluate the performance of \toolSafer{} using the novel data set of labeled \unsafe{} usages, first all instances
with the label \textit{cast-header} are taken from the set.
These are possible misuses involving incorrect constructions of slice and string headers.
There are \checkNum{44} such code samples, which are manually classified as positive and negative examples.
Positive means that the code is a misuse of the \unsafe{} \acrshort{API} and \toolSafer{} should generate a warning for
it, while negative means that the code is a correct and safe usage.
There are \checkNum{30} positive and \checkNum{14} negative samples.

Then, \toolSafer{} is run on all packages that contain the respective \checkNum{44} \unsafe{} usage samples, and all
warnings issued are saved into a \acrshort{CSV} file.
This makes it easy to match the warnings with the labeled samples by their file name and line number.
Samples that are classified as positive are counted as true positives (TP) if \toolSafer{} generated a warning for it,
and false positives (FP) otherwise.
Similarly, negative samples count as false negatives (FN) if there is a warning, and true negatives (TN) otherwise.
Table~\ref{tbl:go-safer-evaluation-dataset} shows the results of this evaluation in its first line.
The other lines contain results from other linters and are discussed in
Section~\ref{subsec:go-safer:evaluation:linters-comparison}.
Furthermore, the table contains the resulting precision, recall, accuracy, and F1-score as calculated from the classes
counts.

\input{assets/tables/chapter5/go-safer-evaluation-dataset.tex}

The results show both high precision and recall of \checkNum{0.967} for \toolSafer{}.
High precision means that there are few false positives, so the warnings generated by \toolSafer{} are almost always
correct and show evidence of an actual bug in the code.
Therefore, developers can include it into their workflows without the need of dismissing many invalid warnings.
A high recall shows that there are few false negatives, therefore a high fraction of the existing bugs is detected by
\toolSafer{}.
Developers thus have a reliable tool at hand to be trusted in detecting bugs of the particular class of \unsafe{}
misuses that it is specialized in.
Accuracy and F1-score are high as well, which follows from both high precision and recall and emphasizes the benefit
quality \toolSafer{} provides.


%% ---------------------------------------------------------------------------------------------------------------------

\subsection{Case Studies}\label{subsec:go-safer:evaluation:case-studies}

A second evaluation of \toolSafer{} is done by manually analyzing \checkNum{six} selected Go packages from open-source
projects.

\input{assets/tables/chapter5/go-safer-evaluation-packages.tex}


%% ---------------------------------------------------------------------------------------------------------------------

\subsection{Comparison with Existing Tools}\label{subsec:go-safer:evaluation:linters-comparison}

Go vet / Gosec
